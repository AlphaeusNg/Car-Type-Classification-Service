{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f4add6fe",
   "metadata": {},
   "source": [
    "# Car Type Classification - Assignment\n",
    "\n",
    "## System Information\n",
    "- **Development Environment**: WSL2 Ubuntu on Windows\n",
    "- **Python Version**: 3.12\n",
    "- **TensorFlow Version**: 2.19.0 with GPU support\n",
    "- **Platform**: Linux (WSL2) - Recommended for optimal performance\n",
    "\n",
    "## Setup Notes\n",
    "This notebook was developed and tested on WSL2 Ubuntu for the best TensorFlow performance with GPU acceleration. For setup instructions for different platforms (Windows native, Linux, WSL2), please refer to the README.md file.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e66938ad",
   "metadata": {},
   "source": [
    "# 1. Environment Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f992a67f",
   "metadata": {},
   "source": [
    "## Objective\n",
    "Set up a Python environment with all necessary dependencies to support data processing, model training, and API development.\n",
    "\n",
    "**Thought process: To ensure efficient training, especially for large datasets like Stanford Cars, we need GPU acceleration. WSL2 on Windows is chosen for its Linux environment, optimal for TensorFlow 2.19.0 with GPU support. We'll verify TensorFlow version and GPU availability to confirm setup, using libraries like NumPy for data handling and ensuring reproducibility with random seeds.**\n",
    "\n",
    "## Steps\n",
    "\n",
    "**System Environment**: This notebook is being run on WSL2 Ubuntu, which provides optimal performance for TensorFlow with GPU acceleration support.\n",
    "\n",
    "**Python Version**: Python 3.12 is used to ensure compatibility with TensorFlow 2.19.0 and FastAPI.\n",
    "\n",
    "**Framework Choice**: The assessment allows TensorFlow 2.x (Keras) or PyTorch. This implementation uses TensorFlow 2.19.0 with Keras for its robust integration with pre-trained models and excellent GPU support on Linux/WSL2.\n",
    "\n",
    "**Dependencies**: All required libraries are installed via the requirements.txt file optimized for Linux/WSL2. For platform-specific installation instructions, refer to README.md.\n",
    "\n",
    "**GPU Support**: This setup leverages CUDA acceleration when available, significantly improving training performance compared to CPU-only execution.\n",
    "\n",
    "## GPU Setup (Optional but Recommended)\n",
    "\n",
    "For optimal performance with GPU acceleration, install CUDA and cuDNN:\n",
    "\n",
    "### Linux/WSL2 CUDA Installation\n",
    "\n",
    "1. **Visit NVIDIA CUDA Downloads**:\n",
    "   - **Ubuntu 24.04**: https://developer.nvidia.com/cuda-downloads?target_os=Linux&target_arch=x86_64&Distribution=Ubuntu&target_version=24.04&target_type=deb_network\n",
    "   - **Other distributions**: https://developer.nvidia.com/cuda-downloads\n",
    "\n",
    "2. **Install CUDA Toolkit** (follow NVIDIA's instructions):\n",
    "   ```bash\n",
    "   # Example for Ubuntu 24.04 - verify commands on NVIDIA's site\n",
    "   wget https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2404/x86_64/cuda-keyring_1.1-1_all.deb\n",
    "   sudo dpkg -i cuda-keyring_1.1-1_all.deb\n",
    "   sudo apt-get update\n",
    "   sudo apt-get -y install cuda-toolkit-12-4\n",
    "   ```\n",
    "\n",
    "3. **Verify installation**:\n",
    "   ```bash\n",
    "   nvidia-smi\n",
    "   nvcc --version\n",
    "   ```\n",
    "\n",
    "4. **Install cuDNN** from https://developer.nvidia.com/cudnn\n",
    "\n",
    "### Windows GPU Support\n",
    "- **Recommended**: Use WSL2 with Ubuntu and follow the Linux instructions above\n",
    "- **Alternative**: Install CUDA for Windows from https://developer.nvidia.com/cuda-downloads?target_os=Windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1cb0be9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-24 02:29:53.246981: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1753295393.255402   15864 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1753295393.258104   15864 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1753295393.265247   15864 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1753295393.265260   15864 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1753295393.265261   15864 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1753295393.265262   15864 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸš€ Car Classification Environment\n",
      "========================================\n",
      "TensorFlow version: 2.19.0\n",
      "Operating System: Linux\n",
      "Architecture: x86_64\n",
      "ğŸ§ Linux detected: Checking for GPU support...\n",
      "GPU devices detected: 1\n",
      "ğŸ‰ GPU DETECTED!\n",
      "  ğŸ® GPU 0: PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')\n",
      "âœ… GPU memory growth enabled\n",
      "âœ… Mixed precision enabled for optimal GPU performance\n",
      "âš¡ Enabling CPU optimizations...\n",
      "âœ… Environment ready for car classification training!\n",
      "ğŸ“Š Performance optimized for your hardware configuration\n"
     ]
    }
   ],
   "source": [
    "# Main imports for Car Classification Project\n",
    "import os\n",
    "\n",
    "# Configure TensorFlow environment before importing TF\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'  # Suppress INFO and WARNING messages\n",
    "os.environ['TF_ENABLE_ONEDNN_OPTS'] = '0'  # Disable oneDNN warnings\n",
    "os.environ['TF_GPU_ALLOCATOR'] = 'cuda_malloc_async'  # Better GPU memory management\n",
    "\n",
    "import platform\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "# Suppress TensorFlow logging\n",
    "tf.get_logger().setLevel('ERROR')\n",
    "\n",
    "print(\"ğŸš€ Car Classification Environment\")\n",
    "print(\"=\" * 40)\n",
    "print(f\"TensorFlow version: {tf.__version__}\")\n",
    "print(f\"Operating System: {platform.system()}\")\n",
    "print(f\"Architecture: {platform.machine()}\")\n",
    "\n",
    "# Check for GPU availability (OS-dependent)\n",
    "system = platform.system().lower()\n",
    "\n",
    "if system == 'windows':\n",
    "    print(\"ğŸªŸ Windows detected: Running in CPU-only mode\")\n",
    "    print(\"ğŸ’¡ For GPU support on Windows, consider using WSL2 or Docker\")\n",
    "    print(\"ğŸš€ Your RTX 4060 can still be used via WSL2 if needed\")\n",
    "    \n",
    "elif system == 'linux':\n",
    "    print(\"ğŸ§ Linux detected: Checking for GPU support...\")\n",
    "    gpus = tf.config.list_physical_devices('GPU')\n",
    "    print(f\"GPU devices detected: {len(gpus)}\")\n",
    "    \n",
    "    if gpus:\n",
    "        print(\"ğŸ‰ GPU DETECTED!\")\n",
    "        for i, gpu in enumerate(gpus):\n",
    "            print(f\"  ğŸ® GPU {i}: {gpu}\")\n",
    "        \n",
    "        # Configure GPU memory growth to prevent allocation errors\n",
    "        try:\n",
    "            for gpu in gpus:\n",
    "                tf.config.experimental.set_memory_growth(gpu, True)\n",
    "            print(\"âœ… GPU memory growth enabled\")\n",
    "        except RuntimeError:\n",
    "            print(\"âš ï¸ GPU memory growth already configured\")\n",
    "        \n",
    "        # Enable mixed precision for better performance\n",
    "        try:\n",
    "            tf.keras.mixed_precision.set_global_policy('mixed_float16')\n",
    "            print(\"âœ… Mixed precision enabled for optimal GPU performance\")\n",
    "        except Exception as e:\n",
    "            print(f\"âš ï¸ Mixed precision setup: {e}\")\n",
    "    else:\n",
    "        print(\"âš ï¸ No GPU detected - using CPU\")\n",
    "        print(\"ğŸ’¡ For GPU setup, run the troubleshooting cell below\")\n",
    "        \n",
    "elif system == 'darwin':\n",
    "    print(\"ğŸ macOS detected: Optimized for Apple hardware\")\n",
    "    if 'arm' in platform.machine().lower():\n",
    "        print(\"ğŸš€ Apple Silicon detected: Using optimized Metal Performance Shaders\")\n",
    "    else:\n",
    "        print(\"ğŸ’» Intel Mac: CPU-only mode\")\n",
    "\n",
    "# CPU optimizations for all platforms\n",
    "print(\"âš¡ Enabling CPU optimizations...\")\n",
    "tf.config.threading.set_inter_op_parallelism_threads(0)  # Use all available cores\n",
    "tf.config.threading.set_intra_op_parallelism_threads(0)  # Use all available cores\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "print(\"âœ… Environment ready for car classification training!\")\n",
    "print(\"ğŸ“Š Performance optimized for your hardware configuration\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f03ab6c5",
   "metadata": {},
   "source": [
    "## Verify System and GPU is OK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4027711c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== System Information ===\n",
      "Platform: Linux-6.6.87.2-microsoft-standard-WSL2-x86_64-with-glibc2.39\n",
      "System: Linux\n",
      "Python Version: 3.12.3 (main, Jun 18 2025, 17:59:45) [GCC 13.3.0]\n",
      "TensorFlow Version: 2.19.0\n",
      "GPU Available: True\n",
      "Number of GPUs: 1\n",
      "âœ… GPU Details:\n",
      "  GPU 0: PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')\n",
      "âœ… GPU memory growth configured\n",
      "\n",
      "=== CUDA Environment Check ===\n",
      "âœ… CUDA found at: /usr/local/cuda/bin/nvcc\n",
      "âœ… cuDNN found at: /usr/lib/x86_64-linux-gnu/libcudnn.so\n",
      "\n",
      "=== Performance Optimization ===\n",
      "ğŸ® GPU acceleration enabled\n",
      "âœ… Mixed precision enabled for optimal GPU performance\n",
      "\n",
      "=== Environment Status ===\n",
      "ğŸ‰ GPU setup complete!\n",
      "ğŸ“ˆ Training will use GPU acceleration\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "# System verification and comprehensive GPU troubleshooting\n",
    "import platform\n",
    "import sys\n",
    "import os\n",
    "\n",
    "print(\"=== System Information ===\")\n",
    "print(f\"Platform: {platform.platform()}\")\n",
    "print(f\"System: {platform.system()}\")\n",
    "print(f\"Python Version: {sys.version}\")\n",
    "print(f\"TensorFlow Version: {tf.__version__}\")\n",
    "\n",
    "# Check GPU availability\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "print(f\"GPU Available: {len(physical_devices) > 0}\")\n",
    "print(f\"Number of GPUs: {len(physical_devices)}\")\n",
    "\n",
    "if len(physical_devices) > 0:\n",
    "    print(\"âœ… GPU Details:\")\n",
    "    for i, device in enumerate(physical_devices):\n",
    "        print(f\"  GPU {i}: {device}\")\n",
    "        \n",
    "    # Configure GPU memory growth to avoid allocation errors\n",
    "    try:\n",
    "        for gpu in physical_devices:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        print(\"âœ… GPU memory growth configured\")\n",
    "    except RuntimeError as e:\n",
    "        print(f\"âš ï¸ GPU memory configuration failed: {e}\")\n",
    "else:\n",
    "    print(\"âš ï¸ No GPU detected\")\n",
    "    print(\"\\nğŸ”§ GPU Troubleshooting Steps:\")\n",
    "    print(\"1. Check if NVIDIA GPU is available:\")\n",
    "    print(\"   Run: nvidia-smi\")\n",
    "    print(\"2. Install CUDA Toolkit:\")\n",
    "    print(\"   Visit: https://developer.nvidia.com/cuda-downloads\")\n",
    "    print(\"3. Install cuDNN:\")\n",
    "    print(\"   Visit: https://developer.nvidia.com/cudnn\")\n",
    "    print(\"4. Verify CUDA installation:\")\n",
    "    print(\"   Run: nvcc --version\")\n",
    "    print(\"5. Check TensorFlow GPU installation:\")\n",
    "    print(\"   Run: python -c 'import tensorflow as tf; print(tf.config.list_physical_devices())'\")\n",
    "\n",
    "print(\"\\n=== CUDA Environment Check ===\")\n",
    "# Check for CUDA installation\n",
    "cuda_paths = [\n",
    "    \"/usr/local/cuda/bin/nvcc\",\n",
    "    \"/usr/bin/nvcc\",\n",
    "    \"/opt/cuda/bin/nvcc\"\n",
    "]\n",
    "\n",
    "cuda_found = False\n",
    "for path in cuda_paths:\n",
    "    if os.path.exists(path):\n",
    "        print(f\"âœ… CUDA found at: {path}\")\n",
    "        cuda_found = True\n",
    "        break\n",
    "\n",
    "if not cuda_found:\n",
    "    print(\"âŒ CUDA not found in common locations\")\n",
    "    print(\"ğŸ’¡ Install CUDA from: https://developer.nvidia.com/cuda-downloads\")\n",
    "\n",
    "# Check for cuDNN\n",
    "# Use existing cudnn_paths variable if present, otherwise define common locations\n",
    "cudnn_paths = []\n",
    "if 'cudnn_paths' not in globals():\n",
    "    cudnn_paths = [\n",
    "        \"/usr/local/cuda/include/cudnn.h\",\n",
    "        \"/usr/include/cudnn.h\",\n",
    "        \"/usr/local/cuda/lib64/libcudnn.so\",\n",
    "        \"/usr/lib/x86_64-linux-gnu/libcudnn.so\",\n",
    "        \"/usr/local/cuda/lib64/libcudnn_ops_infer.so\",\n",
    "        \"/usr/local/cuda/lib64/libcudnn_ops_train.so\",\n",
    "        \"/usr/local/cuda/lib64/libcudnn_adv_infer.so\",\n",
    "        \"/usr/local/cuda/lib64/libcudnn_adv_train.so\",\n",
    "        \"/usr/local/cuda/lib64/libcudnn_cnn_infer.so\",\n",
    "        \"/usr/local/cuda/lib64/libcudnn_cnn_train.so\",\n",
    "        \"/usr/lib/x86_64-linux-gnu/include/cudnn.h\",\n",
    "        \"/usr/lib64/include/cudnn.h\"\n",
    "    ]\n",
    "else:\n",
    "    # Optionally, extend the existing cudnn_paths with more locations\n",
    "    cudnn_paths.extend([\n",
    "        \"/usr/local/cuda/lib64/libcudnn.so\",\n",
    "        \"/usr/lib/x86_64-linux-gnu/libcudnn.so\",\n",
    "        \"/usr/local/cuda/lib64/libcudnn_ops_infer.so\",\n",
    "        \"/usr/local/cuda/lib64/libcudnn_ops_train.so\",\n",
    "        \"/usr/local/cuda/lib64/libcudnn_adv_infer.so\",\n",
    "        \"/usr/local/cuda/lib64/libcudnn_adv_train.so\",\n",
    "        \"/usr/local/cuda/lib64/libcudnn_cnn_infer.so\",\n",
    "        \"/usr/local/cuda/lib64/libcudnn_cnn_train.so\",\n",
    "        \"/usr/lib/x86_64-linux-gnu/include/cudnn.h\",\n",
    "        \"/usr/lib64/include/cudnn.h\"\n",
    "    ])\n",
    "\n",
    "cudnn_found = False\n",
    "for path in cudnn_paths:\n",
    "    if os.path.exists(path):\n",
    "        print(f\"âœ… cuDNN found at: {path}\")\n",
    "        cudnn_found = True\n",
    "        break\n",
    "\n",
    "if not cudnn_found:\n",
    "    print(\"âŒ cuDNN not found\")\n",
    "    print(\"ğŸ’¡ Install cuDNN from: https://developer.nvidia.com/cudnn\")\n",
    "\n",
    "print(\"\\n=== Performance Optimization ===\")\n",
    "if len(physical_devices) > 0:\n",
    "    print(\"ğŸ® GPU acceleration enabled\")\n",
    "    # Enable mixed precision for better GPU performance\n",
    "    try:\n",
    "        tf.keras.mixed_precision.set_global_policy('mixed_float16')\n",
    "        print(\"âœ… Mixed precision enabled for optimal GPU performance\")\n",
    "    except Exception as e:\n",
    "        print(f\"âš ï¸ Mixed precision setup failed: {e}\")\n",
    "else:\n",
    "    print(\"ğŸ’» CPU-only mode - optimizing for CPU performance\")\n",
    "    # CPU optimizations\n",
    "    tf.config.threading.set_inter_op_parallelism_threads(0)\n",
    "    tf.config.threading.set_intra_op_parallelism_threads(0)\n",
    "    print(\"âœ… CPU threading optimized for maximum performance\")\n",
    "\n",
    "print(\"\\n=== Environment Status ===\")\n",
    "if len(physical_devices) > 0:\n",
    "    print(\"ğŸ‰ GPU setup complete!\")\n",
    "    print(\"ğŸ“ˆ Training will use GPU acceleration\")\n",
    "else:\n",
    "    print(\"âœ… CPU setup complete!\")\n",
    "    print(\"ğŸ“Š Training will use optimized CPU performance\")\n",
    "    print(\"â±ï¸ Expected training time: 2-3x longer than GPU (still manageable)\")\n",
    "\n",
    "print(\"=\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7edbf4b",
   "metadata": {},
   "source": [
    "## If there exists GPU issue, please run the cell below to troubleshoot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0a4a7293",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” GPU Troubleshooting Assistant\n",
      "========================================\n",
      "\n",
      "1ï¸âƒ£ Checking NVIDIA GPU...\n",
      "âœ… NVIDIA GPU detected:\n",
      "   ğŸ® |   0  NVIDIA GeForce RTX 4060        On  |   00000000:01:00.0  On |                  N/A |\n",
      "\n",
      "2ï¸âƒ£ Checking CUDA installation...\n",
      "âœ… CUDA installed:\n",
      "   ğŸ“¦ Cuda compilation tools, release 12.9, V12.9.86\n",
      "\n",
      "3ï¸âƒ£ Checking CUDA environment...\n",
      "   CUDA_HOME: /usr/local/cuda\n",
      "\n",
      "4ï¸âƒ£ Checking TensorFlow GPU support...\n",
      "âœ… TensorFlow can see 1 GPU(s)\n",
      "   ğŸ® GPU 0: PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')\n",
      "âœ… GPU computation test successful\n",
      "\n",
      "5ï¸âƒ£ Quick Fix Commands (if needed):\n",
      "   # Install NVIDIA drivers\n",
      "   sudo apt update && sudo apt install nvidia-driver-535\n",
      "   \n",
      "   # Install CUDA (Ubuntu 24.04)\n",
      "   wget https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2404/x86_64/cuda-keyring_1.1-1_all.deb\n",
      "   sudo dpkg -i cuda-keyring_1.1-1_all.deb\n",
      "   sudo apt-get update\n",
      "   sudo apt-get -y install cuda-toolkit-12-4\n",
      "   \n",
      "   # Add to ~/.bashrc\n",
      "   echo 'export CUDA_HOME=/usr/local/cuda' >> ~/.bashrc\n",
      "   echo 'export PATH=$CUDA_HOME/bin:$PATH' >> ~/.bashrc\n",
      "   echo 'export LD_LIBRARY_PATH=$CUDA_HOME/lib64:$LD_LIBRARY_PATH' >> ~/.bashrc\n",
      "   source ~/.bashrc\n",
      "\n",
      "========================================\n",
      "ğŸ”„ After installing CUDA, restart your kernel: Kernel â†’ Restart Kernel\n",
      "âœ… GPU computation test successful\n",
      "\n",
      "5ï¸âƒ£ Quick Fix Commands (if needed):\n",
      "   # Install NVIDIA drivers\n",
      "   sudo apt update && sudo apt install nvidia-driver-535\n",
      "   \n",
      "   # Install CUDA (Ubuntu 24.04)\n",
      "   wget https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2404/x86_64/cuda-keyring_1.1-1_all.deb\n",
      "   sudo dpkg -i cuda-keyring_1.1-1_all.deb\n",
      "   sudo apt-get update\n",
      "   sudo apt-get -y install cuda-toolkit-12-4\n",
      "   \n",
      "   # Add to ~/.bashrc\n",
      "   echo 'export CUDA_HOME=/usr/local/cuda' >> ~/.bashrc\n",
      "   echo 'export PATH=$CUDA_HOME/bin:$PATH' >> ~/.bashrc\n",
      "   echo 'export LD_LIBRARY_PATH=$CUDA_HOME/lib64:$LD_LIBRARY_PATH' >> ~/.bashrc\n",
      "   source ~/.bashrc\n",
      "\n",
      "========================================\n",
      "ğŸ”„ After installing CUDA, restart your kernel: Kernel â†’ Restart Kernel\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1753295394.958595   15864 gpu_process_state.cc:208] Using CUDA malloc Async allocator for GPU: 0\n",
      "I0000 00:00:1753295394.960514   15864 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5563 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4060, pci bus id: 0000:01:00.0, compute capability: 8.9\n"
     ]
    }
   ],
   "source": [
    "# ğŸ”§ GPU Troubleshooting and Setup Assistant\n",
    "# Run this cell if you're experiencing GPU issues\n",
    "\n",
    "import subprocess\n",
    "import os\n",
    "\n",
    "def run_command(command, description):\n",
    "    \"\"\"Run a system command and return the result\"\"\"\n",
    "    try:\n",
    "        result = subprocess.run(command, shell=True, capture_output=True, text=True, timeout=10)\n",
    "        if result.returncode == 0:\n",
    "            return True, result.stdout.strip()\n",
    "        else:\n",
    "            return False, result.stderr.strip()\n",
    "    except subprocess.TimeoutExpired:\n",
    "        return False, \"Command timed out\"\n",
    "    except Exception as e:\n",
    "        return False, str(e)\n",
    "\n",
    "print(\"ğŸ” GPU Troubleshooting Assistant\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "# 1. Check NVIDIA GPU\n",
    "print(\"\\n1ï¸âƒ£ Checking NVIDIA GPU...\")\n",
    "success, output = run_command(\"nvidia-smi\", \"NVIDIA GPU check\")\n",
    "if success:\n",
    "    print(\"âœ… NVIDIA GPU detected:\")\n",
    "    # Extract GPU info from nvidia-smi output\n",
    "    lines = output.split('\\n')\n",
    "    for line in lines:\n",
    "        if 'RTX' in line or 'GTX' in line or 'Tesla' in line or 'GeForce' in line:\n",
    "            print(f\"   ğŸ® {line.strip()}\")\n",
    "else:\n",
    "    print(\"âŒ NVIDIA GPU not detected or nvidia-smi not available\")\n",
    "    print(\"ğŸ’¡ Possible solutions:\")\n",
    "    print(\"   - Install NVIDIA drivers: sudo apt update && sudo apt install nvidia-driver-xxx\")\n",
    "    print(\"   - Check if GPU is properly connected\")\n",
    "    print(\"   - Restart your system after driver installation\")\n",
    "\n",
    "# 2. Check CUDA installation\n",
    "print(\"\\n2ï¸âƒ£ Checking CUDA installation...\")\n",
    "success, output = run_command(\"nvcc --version\", \"CUDA compiler check\")\n",
    "if success:\n",
    "    print(\"âœ… CUDA installed:\")\n",
    "    for line in output.split('\\n'):\n",
    "        if 'release' in line.lower():\n",
    "            print(f\"   ğŸ“¦ {line.strip()}\")\n",
    "else:\n",
    "    print(\"âŒ CUDA not installed or not in PATH\")\n",
    "    print(\"ğŸ’¡ Install CUDA:\")\n",
    "    print(\"   Ubuntu 24.04: https://developer.nvidia.com/cuda-downloads?target_os=Linux&target_arch=x86_64&Distribution=Ubuntu&target_version=24.04&target_type=deb_network\")\n",
    "\n",
    "# 3. Check CUDA environment variables\n",
    "print(\"\\n3ï¸âƒ£ Checking CUDA environment...\")\n",
    "cuda_home = os.environ.get('CUDA_HOME', os.environ.get('CUDA_PATH', 'Not set'))\n",
    "ld_library_path = os.environ.get('LD_LIBRARY_PATH', 'Not set')\n",
    "\n",
    "print(f\"   CUDA_HOME: {cuda_home}\")\n",
    "if 'cuda' not in cuda_home.lower():\n",
    "    print(\"   âš ï¸ CUDA_HOME not properly set\")\n",
    "    print(\"   ğŸ’¡ Add to ~/.bashrc: export CUDA_HOME=/usr/local/cuda\")\n",
    "\n",
    "# 4. Check TensorFlow GPU support\n",
    "print(\"\\n4ï¸âƒ£ Checking TensorFlow GPU support...\")\n",
    "try:\n",
    "    import tensorflow as tf\n",
    "    \n",
    "    # Suppress warnings for this check\n",
    "    tf.get_logger().setLevel('ERROR')\n",
    "    \n",
    "    gpus = tf.config.list_physical_devices('GPU')\n",
    "    if gpus:\n",
    "        print(f\"âœ… TensorFlow can see {len(gpus)} GPU(s)\")\n",
    "        for i, gpu in enumerate(gpus):\n",
    "            print(f\"   ğŸ® GPU {i}: {gpu}\")\n",
    "        \n",
    "        # Test GPU computation\n",
    "        try:\n",
    "            with tf.device('/GPU:0'):\n",
    "                a = tf.constant([[1.0, 2.0, 3.0], [4.0, 5.0, 6.0]])\n",
    "                b = tf.constant([[1.0, 2.0], [3.0, 4.0], [5.0, 6.0]])\n",
    "                c = tf.matmul(a, b)\n",
    "            print(\"âœ… GPU computation test successful\")\n",
    "        except Exception as e:\n",
    "            print(f\"âŒ GPU computation test failed: {e}\")\n",
    "    else:\n",
    "        print(\"âŒ TensorFlow cannot detect GPU\")\n",
    "        print(\"ğŸ’¡ Possible solutions:\")\n",
    "        print(\"   - Reinstall TensorFlow with GPU support: pip install tensorflow[and-cuda]\")\n",
    "        print(\"   - Check CUDA compatibility: https://www.tensorflow.org/install/source#gpu\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"âŒ TensorFlow import failed: {e}\")\n",
    "\n",
    "# 5. Provide installation commands\n",
    "print(\"\\n5ï¸âƒ£ Quick Fix Commands (if needed):\")\n",
    "print(\"   # Install NVIDIA drivers\")\n",
    "print(\"   sudo apt update && sudo apt install nvidia-driver-535\")\n",
    "print(\"   \")\n",
    "print(\"   # Install CUDA (Ubuntu 24.04)\")\n",
    "print(\"   wget https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2404/x86_64/cuda-keyring_1.1-1_all.deb\")\n",
    "print(\"   sudo dpkg -i cuda-keyring_1.1-1_all.deb\")\n",
    "print(\"   sudo apt-get update\")\n",
    "print(\"   sudo apt-get -y install cuda-toolkit-12-4\")\n",
    "print(\"   \")\n",
    "print(\"   # Add to ~/.bashrc\")\n",
    "print(\"   echo 'export CUDA_HOME=/usr/local/cuda' >> ~/.bashrc\")\n",
    "print(\"   echo 'export PATH=$CUDA_HOME/bin:$PATH' >> ~/.bashrc\")\n",
    "print(\"   echo 'export LD_LIBRARY_PATH=$CUDA_HOME/lib64:$LD_LIBRARY_PATH' >> ~/.bashrc\")\n",
    "print(\"   source ~/.bashrc\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 40)\n",
    "print(\"ğŸ”„ After installing CUDA, restart your kernel: Kernel â†’ Restart Kernel\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ae5deda",
   "metadata": {},
   "source": [
    "# ğŸ¯ **Quick Start Guide - TensorFlow 2.19.0**\n",
    "\n",
    "## Getting Started (Cross-Platform)\n",
    "\n",
    "### 0ï¸âƒ£ **GPU Setup (Optional but Recommended)**\n",
    "For optimal performance, install CUDA and cuDNN first:\n",
    "- **Ubuntu 24.04**: https://developer.nvidia.com/cuda-downloads?target_os=Linux&target_arch=x86_64&Distribution=Ubuntu&target_version=24.04&target_type=deb_network\n",
    "- **Other OS**: https://developer.nvidia.com/cuda-downloads\n",
    "- Follow NVIDIA's installation instructions for your specific OS\n",
    "\n",
    "### 1ï¸âƒ£ **Install Dependencies**\n",
    "Run the installation cells above:\n",
    "- âœ… **Auto-detects** your OS and Python version\n",
    "- âœ… **Downloads correct** TensorFlow wheel for your system\n",
    "- âœ… **Installs all** required dependencies\n",
    "\n",
    "### 2ï¸âƒ£ **Restart Kernel**  \n",
    "Go to **Kernel â†’ Restart Kernel** in VS Code\n",
    "\n",
    "### 3ï¸âƒ£ **Verify Setup**\n",
    "Re-run the imports cell to verify everything works\n",
    "\n",
    "### 4ï¸âƒ£ **Start Training**\n",
    "Continue with the car classification cells below!\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ–¥ï¸ **Platform-Specific Notes**\n",
    "\n",
    "### ğŸ§ **Linux/WSL2 (Recommended)**\n",
    "- **GPU Support**: Full CUDA acceleration available with proper setup\n",
    "- **Best Performance**: Ideal for intensive training workloads\n",
    "- **CUDA Guide**: Follow the Ubuntu 24.04 link above for your distribution\n",
    "\n",
    "### ğŸªŸ **Windows**\n",
    "- **GPU Support**: Use WSL2 for full GPU acceleration\n",
    "- **CPU-only**: Still excellent performance with multi-core optimization\n",
    "- **Training time**: ~2-3x longer than GPU, but manageable for this project\n",
    "- **Memory**: 16GB+ RAM recommended for larger batch sizes\n",
    "\n",
    "### ğŸ **macOS**\n",
    "- **Apple Silicon**: Optimized for M1/M2/M3 chips\n",
    "- **Intel**: CPU-only, still very capable\n",
    "\n",
    "**TensorFlow 2.19 brings improved CPU performance across all platforms!** ğŸš€"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e94ab38e",
   "metadata": {},
   "source": [
    "# 2. Data Loading and Preprocessing\n",
    "\n",
    "## Objective\n",
    "Prepare the Stanford Cars Dataset for training by downloading, preprocessing, and splitting it into appropriate sets.\n",
    "\n",
    "**Thought Process: The Stanford Cars Dataset has 196 classes, requiring robust preprocessing. We'll download via KaggleHub for reliability, resize to 224x224 for ResNet50, normalize pixels for consistency, and use augmentation to handle variations. Splitting into train/validation/test sets, with 20% validation from training, ensures proper evaluation.**\n",
    "\n",
    "## Dataset Details\n",
    "Source: The Stanford Cars Dataset contains 16,185 images across 196 classes (Make, Model, Year), with 8,144 training and 8,041 testing images. Images are approximately 360x240 pixels.\n",
    "\n",
    "Download: Access the dataset from Kaggle or the official site (note: the official URL seems to be broken, so I'll download from Kaggle).\n",
    "\n",
    "Structure: The dataset includes images and annotations in .mat format, requiring scipy to load.\n",
    "\n",
    "## Preprocessing Steps\n",
    "Resize Images: Resize images to 224x224 pixels to match the input size of pre-trained models like ResNet50.\n",
    "\n",
    "Normalization: Scale pixel values to [0, 1] by dividing by 255.\n",
    "\n",
    "Augmentation: Apply random flips, rotations, and color jitter to improve model generalization.\n",
    "\n",
    "Data Splitting: Use the provided train/test split. Create a validation set by taking 20% of the training data (approximately 1,629 images)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6a34fcd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to dataset files: /home/alph/.cache/kagglehub/datasets/cyizhuo/stanford-cars-by-classes-folder/versions/5\n"
     ]
    }
   ],
   "source": [
    "import kagglehub\n",
    "\n",
    "# Download latest version\n",
    "download_path = kagglehub.dataset_download(\"cyizhuo/stanford-cars-by-classes-folder\")\n",
    "\n",
    "print(\"Path to dataset files:\", download_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "daba44e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¯ STANFORD CARS DATASET DETECTION AND ORGANIZATION\n",
      "============================================================\n",
      "ğŸ” DETECTING DATASET STRUCTURE...\n",
      "==================================================\n",
      "ğŸ” Checking: /home/alph/.cache/kagglehub/datasets/cyizhuo/stanford-cars-by-classes-folder/versions/5\n",
      "   âœ… Found structure type: direct_train_test\n",
      "   ğŸ“ Train folder: /home/alph/.cache/kagglehub/datasets/cyizhuo/stanford-cars-by-classes-folder/versions/5/train (âœ…)\n",
      "   ğŸ“ Test folder: /home/alph/.cache/kagglehub/datasets/cyizhuo/stanford-cars-by-classes-folder/versions/5/test (âœ…)\n",
      "   ğŸ“Š Classes found: 196 (showing first 10)\n",
      "       1. Jeep Liberty SUV 2012\n",
      "       2. Maybach Landaulet Convertible 2012\n",
      "       3. Audi V8 Sedan 1994\n",
      "       4. Mercedes-Benz C-Class Sedan 2012\n",
      "       5. BMW M5 Sedan 2010\n",
      "       6. Ford Mustang Convertible 2007\n",
      "       7. BMW ActiveHybrid 5 Sedan 2012\n",
      "       8. Acura TL Type-S 2008\n",
      "       9. HUMMER H2 SUT Crew Cab 2009\n",
      "      10. BMW M3 Coupe 2012\n",
      "      ... and 186 more classes\n",
      "   ğŸ–¼ï¸ Total training images: 8144\n",
      "\n",
      "ğŸ‰ Dataset found!\n",
      "ğŸ“ Location: /home/alph/.cache/kagglehub/datasets/cyizhuo/stanford-cars-by-classes-folder/versions/5\n",
      "ğŸ—ï¸ Structure type: direct_train_test\n",
      "\n",
      "ğŸ”§ ORGANIZING DATASET STRUCTURE...\n",
      "==================================================\n",
      "ğŸ“ Organizing training data from: /home/alph/.cache/kagglehub/datasets/cyizhuo/stanford-cars-by-classes-folder/versions/5/train\n",
      "   âœ… Training data already organized\n",
      "ğŸ“ Organizing test data from: /home/alph/.cache/kagglehub/datasets/cyizhuo/stanford-cars-by-classes-folder/versions/5/test\n",
      "   âœ… Test data already organized\n",
      "\n",
      "âœ… DATASET ORGANIZATION COMPLETE!\n",
      "ğŸ“Š Training classes: 196\n",
      "ğŸ“Š Test classes: 196\n",
      "ğŸ–¼ï¸ Training images: 8144\n",
      "ğŸ–¼ï¸ Test images: 8041\n",
      "\n",
      "ğŸ” VERIFYING DATASET COMPATIBILITY...\n",
      "==================================================\n",
      "âœ… Train directory found\n",
      "âœ… Test directory found\n",
      "âœ… Found 196 training classes\n",
      "âœ… All classes contain images\n",
      "ğŸ“Š Image files: 8144\n",
      "\n",
      "âœ… DATASET READY FOR TRAINING!\n",
      "ğŸš€ All checks passed - dataset is compatible with ImageDataGenerator\n",
      "\n",
      "ğŸ¯ DATASET SETUP SUCCESSFUL!\n",
      "âœ… Ready to proceed with model training\n",
      "ğŸ“Š Configuration:\n",
      "   Train directory: data/train\n",
      "   Test directory: data/test\n",
      "   Number of classes: 196\n",
      "\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# ğŸ” Robust Dataset Structure Detection and Organization\n",
    "\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "\n",
    "def detect_dataset_structure(downloaded_path):\n",
    "    \"\"\"\n",
    "    Robustly detect and analyze the Stanford Cars dataset folder structure\n",
    "    Handles multiple possible formats from different sources\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"ğŸ” DETECTING DATASET STRUCTURE...\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # Check all possible locations where dataset might be\n",
    "    possible_paths = [\n",
    "        Path(downloaded_path),\n",
    "        Path(\"data\"),\n",
    "        Path(\".\"),\n",
    "        Path(\"stanford-cars-by-classes-folder\"),\n",
    "        Path(\"~/.cache/kagglehub\").expanduser(),\n",
    "    ]\n",
    "    \n",
    "    dataset_info = {\n",
    "        'found': False,\n",
    "        'location': None,\n",
    "        'structure_type': None,\n",
    "        'train_path': None,\n",
    "        'test_path': None,\n",
    "        'classes': [],\n",
    "        'total_images': 0\n",
    "    }\n",
    "    \n",
    "    for base_path in possible_paths:\n",
    "        if not base_path.exists():\n",
    "            continue\n",
    "            \n",
    "        print(f\"ğŸ” Checking: {base_path.absolute()}\")\n",
    "        \n",
    "        # Look for different possible structures\n",
    "        structures_to_check = [\n",
    "            # Structure 1: Direct train/test folders\n",
    "            {'train': base_path / 'train', 'test': base_path / 'test', 'type': 'direct_train_test'},\n",
    "            {'train': base_path / 'cars_train', 'test': base_path / 'cars_test', 'type': 'cars_prefix'},\n",
    "            \n",
    "            # Structure 2: Nested in subdirectories\n",
    "            {'train': base_path / 'stanford-cars-dataset' / 'train', 'test': base_path / 'stanford-cars-dataset' / 'test', 'type': 'nested_stanford'},\n",
    "            {'train': base_path / 'stanford-cars-by-classes-folder' / 'train', 'test': base_path / 'stanford-cars-by-classes-folder' / 'test', 'type': 'nested_classes'},\n",
    "            \n",
    "            # Structure 3: Single folder with all classes (need to split)\n",
    "            {'train': base_path / 'all_classes', 'test': None, 'type': 'single_folder'},\n",
    "            \n",
    "            # Structure 4: Kagglehub cache structure\n",
    "            {'train': None, 'test': None, 'type': 'kagglehub_cache'},\n",
    "        ]\n",
    "        \n",
    "        for structure in structures_to_check:\n",
    "            if structure['type'] == 'kagglehub_cache':\n",
    "                # Special handling for kagglehub cache\n",
    "                if 'kagglehub' in str(base_path):\n",
    "                    for item in base_path.rglob('*'):\n",
    "                        if item.is_dir() and ('train' in item.name.lower() or 'test' in item.name.lower()):\n",
    "                            print(f\"   ğŸ“ Found kagglehub folder: {item}\")\n",
    "                            dataset_info['found'] = True\n",
    "                            dataset_info['location'] = base_path\n",
    "                            dataset_info['structure_type'] = 'kagglehub_cache'\n",
    "                            break\n",
    "                continue\n",
    "            \n",
    "            train_path = structure['train']\n",
    "            test_path = structure['test']\n",
    "            \n",
    "            # Check if this structure exists\n",
    "            train_exists = train_path and train_path.exists() and train_path.is_dir()\n",
    "            test_exists = test_path and test_path.exists() and test_path.is_dir()\n",
    "            \n",
    "            if train_exists or test_exists:\n",
    "                print(f\"   âœ… Found structure type: {structure['type']}\")\n",
    "                print(f\"   ğŸ“ Train folder: {train_path} ({'âœ…' if train_exists else 'âŒ'})\")\n",
    "                print(f\"   ğŸ“ Test folder: {test_path} ({'âœ…' if test_exists else 'âŒ'})\")\n",
    "                \n",
    "                # Analyze the structure\n",
    "                classes = []\n",
    "                total_images = 0\n",
    "                \n",
    "                if train_exists:\n",
    "                    classes = [d.name for d in train_path.iterdir() if d.is_dir()]\n",
    "                    for class_dir in train_path.iterdir():\n",
    "                        if class_dir.is_dir():\n",
    "                            image_count = len([f for f in class_dir.iterdir() if f.suffix.lower() in ['.jpg', '.jpeg', '.png']])\n",
    "                            total_images += image_count\n",
    "                \n",
    "                dataset_info.update({\n",
    "                    'found': True,\n",
    "                    'location': base_path,\n",
    "                    'structure_type': structure['type'],\n",
    "                    'train_path': train_path if train_exists else None,\n",
    "                    'test_path': test_path if test_exists else None,\n",
    "                    'classes': classes[:10],  # Show first 10 classes\n",
    "                    'total_images': total_images\n",
    "                })\n",
    "                \n",
    "                print(f\"   ğŸ“Š Classes found: {len(classes)} (showing first 10)\")\n",
    "                for i, class_name in enumerate(classes[:10]):\n",
    "                    print(f\"      {i+1:2d}. {class_name}\")\n",
    "                if len(classes) > 10:\n",
    "                    print(f\"      ... and {len(classes) - 10} more classes\")\n",
    "                print(f\"   ğŸ–¼ï¸ Total training images: {total_images}\")\n",
    "                \n",
    "                return dataset_info\n",
    "    \n",
    "    print(\"âŒ No Stanford Cars dataset found in any expected location\")\n",
    "    return dataset_info\n",
    "\n",
    "def organize_dataset_structure(dataset_info):\n",
    "    \"\"\"\n",
    "    Organize the dataset into a standard structure for training\n",
    "    \"\"\"\n",
    "    \n",
    "    if not dataset_info['found']:\n",
    "        print(\"âŒ Cannot organize dataset - no dataset found\")\n",
    "        return None\n",
    "    \n",
    "    print(f\"\\nğŸ”§ ORGANIZING DATASET STRUCTURE...\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # Create standard data directory structure\n",
    "    standard_data_dir = Path(\"data\")\n",
    "    standard_train_dir = standard_data_dir / \"train\"\n",
    "    standard_test_dir = standard_data_dir / \"test\"\n",
    "    \n",
    "    standard_data_dir.mkdir(exist_ok=True)\n",
    "    standard_train_dir.mkdir(exist_ok=True)\n",
    "    standard_test_dir.mkdir(exist_ok=True)\n",
    "    \n",
    "    structure_type = dataset_info['structure_type']\n",
    "    \n",
    "    if structure_type in ['direct_train_test', 'cars_prefix', 'nested_stanford', 'nested_classes']:\n",
    "        # Copy/link existing train and test folders\n",
    "        \n",
    "        if dataset_info['train_path'] and dataset_info['train_path'].exists():\n",
    "            print(f\"ğŸ“ Organizing training data from: {dataset_info['train_path']}\")\n",
    "            \n",
    "            if not any(standard_train_dir.iterdir()):  # Only copy if empty\n",
    "                for class_dir in dataset_info['train_path'].iterdir():\n",
    "                    if class_dir.is_dir():\n",
    "                        dest_class_dir = standard_train_dir / class_dir.name\n",
    "                        if not dest_class_dir.exists():\n",
    "                            print(f\"   ğŸ“‚ Copying class: {class_dir.name}\")\n",
    "                            shutil.copytree(class_dir, dest_class_dir)\n",
    "            else:\n",
    "                print(\"   âœ… Training data already organized\")\n",
    "        \n",
    "        if dataset_info['test_path'] and dataset_info['test_path'].exists():\n",
    "            print(f\"ğŸ“ Organizing test data from: {dataset_info['test_path']}\")\n",
    "            \n",
    "            if not any(standard_test_dir.iterdir()):  # Only copy if empty\n",
    "                for class_dir in dataset_info['test_path'].iterdir():\n",
    "                    if class_dir.is_dir():\n",
    "                        dest_class_dir = standard_test_dir / class_dir.name\n",
    "                        if not dest_class_dir.exists():\n",
    "                            print(f\"   ğŸ“‚ Copying class: {class_dir.name}\")\n",
    "                            shutil.copytree(class_dir, dest_class_dir)\n",
    "            else:\n",
    "                print(\"   âœ… Test data already organized\")\n",
    "    \n",
    "    elif structure_type == 'single_folder':\n",
    "        # Split single folder into train/test (80/20 split)\n",
    "        print(\"ğŸ“ Splitting single folder into train/test sets...\")\n",
    "        \n",
    "        source_path = dataset_info['location']\n",
    "        # Implementation for splitting would go here\n",
    "        print(\"âš ï¸ Single folder splitting not yet implemented - please organize manually\")\n",
    "    \n",
    "    elif structure_type == 'kagglehub_cache':\n",
    "        print(\"ğŸ“ Detecting kagglehub cache structure...\")\n",
    "        # Find the actual dataset files in kagglehub cache\n",
    "        cache_path = dataset_info['location']\n",
    "        \n",
    "        # Look for train/test folders in cache\n",
    "        for item in cache_path.rglob('*'):\n",
    "            if item.is_dir() and 'train' in item.name.lower():\n",
    "                print(f\"   ğŸ“‚ Found train folder: {item}\")\n",
    "                dataset_info['train_path'] = item\n",
    "            elif item.is_dir() and 'test' in item.name.lower():\n",
    "                print(f\"   ğŸ“‚ Found test folder: {item}\")\n",
    "                dataset_info['test_path'] = item\n",
    "        \n",
    "        # Recursive call with updated paths\n",
    "        return organize_dataset_structure(dataset_info)\n",
    "    \n",
    "    # Verify final structure\n",
    "    train_classes = [d.name for d in standard_train_dir.iterdir() if d.is_dir()]\n",
    "    test_classes = [d.name for d in standard_test_dir.iterdir() if d.is_dir()]\n",
    "    \n",
    "    print(f\"\\nâœ… DATASET ORGANIZATION COMPLETE!\")\n",
    "    print(f\"ğŸ“Š Training classes: {len(train_classes)}\")\n",
    "    print(f\"ğŸ“Š Test classes: {len(test_classes)}\")\n",
    "    \n",
    "    # Count images\n",
    "    total_train_images = sum(len([f for f in class_dir.iterdir() if f.suffix.lower() in ['.jpg', '.jpeg', '.png']]) \n",
    "                           for class_dir in standard_train_dir.iterdir() if class_dir.is_dir())\n",
    "    total_test_images = sum(len([f for f in class_dir.iterdir() if f.suffix.lower() in ['.jpg', '.jpeg', '.png']]) \n",
    "                          for class_dir in standard_test_dir.iterdir() if class_dir.is_dir())\n",
    "    \n",
    "    print(f\"ğŸ–¼ï¸ Training images: {total_train_images}\")\n",
    "    print(f\"ğŸ–¼ï¸ Test images: {total_test_images}\")\n",
    "    \n",
    "    return {\n",
    "        'train_dir': standard_train_dir,\n",
    "        'test_dir': standard_test_dir,\n",
    "        'train_classes': train_classes,\n",
    "        'test_classes': test_classes,\n",
    "        'train_images': total_train_images,\n",
    "        'test_images': total_test_images\n",
    "    }\n",
    "\n",
    "def verify_dataset_compatibility():\n",
    "    \"\"\"\n",
    "    Verify that the organized dataset is compatible with Keras ImageDataGenerator\n",
    "    \"\"\"\n",
    "    \n",
    "    print(f\"\\nğŸ” VERIFYING DATASET COMPATIBILITY...\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    data_dir = Path(\"data\")\n",
    "    train_dir = data_dir / \"train\"\n",
    "    test_dir = data_dir / \"test\"\n",
    "    \n",
    "    issues = []\n",
    "    \n",
    "    # Check basic structure\n",
    "    if not train_dir.exists():\n",
    "        issues.append(\"âŒ Train directory missing\")\n",
    "    else:\n",
    "        print(\"âœ… Train directory found\")\n",
    "    \n",
    "    if not test_dir.exists():\n",
    "        issues.append(\"âš ï¸ Test directory missing (optional)\")\n",
    "    else:\n",
    "        print(\"âœ… Test directory found\")\n",
    "    \n",
    "    # Check class structure\n",
    "    if train_dir.exists():\n",
    "        train_classes = [d for d in train_dir.iterdir() if d.is_dir()]\n",
    "        if len(train_classes) == 0:\n",
    "            issues.append(\"âŒ No class folders found in train directory\")\n",
    "        else:\n",
    "            print(f\"âœ… Found {len(train_classes)} training classes\")\n",
    "            \n",
    "            # Check if classes have images\n",
    "            empty_classes = []\n",
    "            for class_dir in train_classes:\n",
    "                image_files = [f for f in class_dir.iterdir() if f.suffix.lower() in ['.jpg', '.jpeg', '.png']]\n",
    "                if len(image_files) == 0:\n",
    "                    empty_classes.append(class_dir.name)\n",
    "            \n",
    "            if empty_classes:\n",
    "                issues.append(f\"âš ï¸ Empty classes found: {', '.join(empty_classes[:5])}\")\n",
    "            else:\n",
    "                print(\"âœ… All classes contain images\")\n",
    "    \n",
    "    # Check file formats\n",
    "    if train_dir.exists():\n",
    "        all_files = list(train_dir.rglob('*'))\n",
    "        image_files = [f for f in all_files if f.is_file() and f.suffix.lower() in ['.jpg', '.jpeg', '.png']]\n",
    "        other_files = [f for f in all_files if f.is_file() and f.suffix.lower() not in ['.jpg', '.jpeg', '.png']]\n",
    "        \n",
    "        print(f\"ğŸ“Š Image files: {len(image_files)}\")\n",
    "        if other_files:\n",
    "            print(f\"âš ï¸ Non-image files: {len(other_files)} (first 5: {[f.name for f in other_files[:5]]})\")\n",
    "    \n",
    "    # Summary\n",
    "    if issues:\n",
    "        print(f\"\\nâš ï¸ ISSUES FOUND:\")\n",
    "        for issue in issues:\n",
    "            print(f\"   {issue}\")\n",
    "        print(\"\\nğŸ’¡ You may need to manually fix these issues before training\")\n",
    "    else:\n",
    "        print(f\"\\nâœ… DATASET READY FOR TRAINING!\")\n",
    "        print(\"ğŸš€ All checks passed - dataset is compatible with ImageDataGenerator\")\n",
    "    \n",
    "    return len(issues) == 0\n",
    "\n",
    "# ğŸš€ Execute Dataset Detection and Organization\n",
    "\n",
    "print(\"ğŸ¯ STANFORD CARS DATASET DETECTION AND ORGANIZATION\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Step 1: Detect dataset structure\n",
    "dataset_info = detect_dataset_structure(download_path)\n",
    "\n",
    "if dataset_info['found']:\n",
    "    print(f\"\\nğŸ‰ Dataset found!\")\n",
    "    print(f\"ğŸ“ Location: {dataset_info['location']}\")\n",
    "    print(f\"ğŸ—ï¸ Structure type: {dataset_info['structure_type']}\")\n",
    "    \n",
    "    # Step 2: Organize dataset\n",
    "    organized_info = organize_dataset_structure(dataset_info)\n",
    "    \n",
    "    if organized_info:\n",
    "        # Step 3: Verify compatibility\n",
    "        is_compatible = verify_dataset_compatibility()\n",
    "        \n",
    "        if is_compatible:\n",
    "            print(f\"\\nğŸ¯ DATASET SETUP SUCCESSFUL!\")\n",
    "            print(\"âœ… Ready to proceed with model training\")\n",
    "            \n",
    "            # Store for later use\n",
    "            DATASET_READY = True\n",
    "            TRAIN_DIR = organized_info['train_dir']\n",
    "            TEST_DIR = organized_info['test_dir']\n",
    "            NUM_CLASSES = len(organized_info['train_classes'])\n",
    "            \n",
    "            print(f\"ğŸ“Š Configuration:\")\n",
    "            print(f\"   Train directory: {TRAIN_DIR}\")\n",
    "            print(f\"   Test directory: {TEST_DIR}\")\n",
    "            print(f\"   Number of classes: {NUM_CLASSES}\")\n",
    "        else:\n",
    "            print(f\"\\nâš ï¸ Dataset has issues - may need manual fixing\")\n",
    "            DATASET_READY = False\n",
    "    else:\n",
    "        print(f\"\\nâŒ Failed to organize dataset\")\n",
    "        DATASET_READY = False\n",
    "else:\n",
    "    print(f\"\\nğŸ“¥ No dataset found. Options:\")\n",
    "    print(\"1. Run the previous cell to download via kagglehub\")\n",
    "    print(\"2. Download manually and place in 'data' folder\")\n",
    "    print(\"3. Continue with demo data for testing\")\n",
    "    DATASET_READY = False\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "46afc12f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ”§ UTILIZING DETECTED DATASET STRUCTURE...\n",
      "==================================================\n",
      "âœ… Dataset ready for use!\n",
      "ğŸ“ Train directory: data/train\n",
      "ğŸ“ Test directory: data/test\n",
      "ğŸ“Š Detected 196 classes from dataset structure\n",
      "ğŸ·ï¸ Sample classes: ['AM General Hummer SUV 2000', 'Acura Integra Type R 2001', 'Acura RL Sedan 2012', 'Acura TL Sedan 2012', 'Acura TL Type-S 2008']\n",
      "\n",
      "ğŸ“ˆ FINAL DATASET CONFIGURATION:\n",
      "   Number of classes: 196\n",
      "   Image size: (224, 224)\n",
      "   Batch size: 32\n",
      "   Training epochs: 20\n",
      "   Train directory: data/train\n",
      "   Test directory: data/test\n",
      "   âœ… Train directory: 196 classes, 8144 images\n",
      "   âœ… Test directory: 196 classes, 8041 images\n",
      "\n",
      "ğŸ’¾ Saving class mapping...\n",
      "âœ… Class mapping saved to 'class_mapping.json'\n",
      "ğŸ“‹ Mapping contains 196 classes\n",
      "\n",
      "ğŸ¯ DATASET SETUP STATUS:\n",
      "âœ… Dataset is ready for model training!\n",
      "ğŸš€ You can proceed to the next cells for data preprocessing and model training\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "def load_stanford_cars_metadata():\n",
    "    \"\"\"\n",
    "    Load Stanford Cars dataset metadata and class information\n",
    "    \"\"\"\n",
    "    print(\"\\nğŸ“Š Loading Stanford Cars Dataset Metadata...\")\n",
    "    \n",
    "    # Stanford Cars class names (196 classes)\n",
    "    car_classes = [\n",
    "        \"AM General Hummer SUV 2000\", \"Acura RL Sedan 2012\", \"Acura TL Sedan 2012\", \n",
    "        \"Acura TL Type-S 2008\", \"Acura TSX Sedan 2012\", \"Acura Integra Type R 2001\",\n",
    "        \"Acura ZDX Hatchback 2012\", \"Aston Martin V8 Vantage Convertible 2012\",\n",
    "        \"Aston Martin V8 Vantage Coupe 2012\", \"Aston Martin Virage Convertible 2012\",\n",
    "        \"Aston Martin Virage Coupe 2012\", \"Audi RS 4 Convertible 2008\",\n",
    "        \"Audi A5 Coupe 2012\", \"Audi TTS Coupe 2012\", \"Audi R8 Coupe 2012\",\n",
    "        \"Audi V8 Sedan 1994\", \"Audi 100 Sedan 1994\", \"Audi 100 Wagon 1994\",\n",
    "        \"Audi TT Hatchback 2011\", \"Audi S6 Sedan 2011\", \"Audi S5 Convertible 2012\",\n",
    "        \"Audi S5 Coupe 2012\", \"Audi S4 Sedan 2007\", \"Audi S4 Sedan 2012\",\n",
    "        \"Audi TT RS Coupe 2012\", \"BMW ActiveHybrid 5 Sedan 2012\", \"BMW 1 Series Convertible 2012\",\n",
    "        \"BMW 1 Series Coupe 2012\", \"BMW 3 Series Sedan 2012\", \"BMW 3 Series Wagon 2012\",\n",
    "        \"BMW 6 Series Convertible 2007\", \"BMW X5 SUV 2007\", \"BMW X6 SUV 2012\",\n",
    "        \"BMW M3 Coupe 2012\", \"BMW M5 Sedan 2010\", \"BMW M6 Convertible 2010\",\n",
    "        \"BMW X3 SUV 2012\", \"BMW Z4 Convertible 2012\", \"Bentley Continental Supersports Conv. Convertible 2012\",\n",
    "        \"Bentley Arnage Sedan 2009\", \"Bentley Mulsanne Sedan 2011\", \"Bentley Continental GT Coupe 2007\",\n",
    "        \"Bentley Continental GT Coupe 2012\", \"Bentley Continental Flying Spur Sedan 2007\",\n",
    "        \"Bugatti Veyron 16.4 Convertible 2009\", \"Bugatti Veyron 16.4 Coupe 2009\",\n",
    "        \"Buick Regal GS 2012\", \"Buick Rainier SUV 2007\", \"Buick Verano Sedan 2012\",\n",
    "        \"Buick Enclave SUV 2012\", \"Cadillac CTS-V Sedan 2011\", \"Cadillac SRX SUV 2012\",\n",
    "        \"Cadillac Escalade EXT Crew Cab 2007\", \"Chevrolet Silverado 1500 Hybrid Crew Cab 2012\",\n",
    "        \"Chevrolet Corvette Convertible 2012\", \"Chevrolet Corvette ZR1 2012\",\n",
    "        \"Chevrolet Corvette Ron Fellows Edition Z06 2007\", \"Chevrolet Traverse SUV 2012\",\n",
    "        \"Chevrolet Camaro Convertible 2012\", \"Chevrolet HHR SS 2010\", \"Chevrolet Impala Sedan 2007\",\n",
    "        \"Chevrolet Tahoe Hybrid SUV 2012\", \"Chevrolet Sonic Sedan 2012\", \"Chevrolet Express Cargo Van 2007\",\n",
    "        \"Chevrolet Avalanche Crew Cab 2012\", \"Chevrolet Cobalt SS 2010\", \"Chevrolet Malibu Hybrid Sedan 2010\",\n",
    "        \"Chevrolet TrailBlazer SS 2009\", \"Chevrolet Silverado 2500HD Regular Cab 2012\",\n",
    "        \"Chevrolet Silverado 1500 Classic Extended Cab 2007\", \"Chevrolet Express Van 2007\",\n",
    "        \"Chevrolet Monte Carlo Coupe 2007\", \"Chevrolet Malibu Sedan 2007\", \"Chevrolet Silverado 1500 Extended Cab 2012\",\n",
    "        \"Chevrolet Silverado 1500 Regular Cab 2012\", \"Chrysler Aspen SUV 2009\", \"Chrysler Sebring Convertible 2010\",\n",
    "        \"Chrysler Town and Country Minivan 2012\", \"Daewoo Nubira Wagon 2002\", \"Dodge Caliber Wagon 2012\",\n",
    "        \"Dodge Caliber Wagon 2007\", \"Dodge Caravan Minivan 1997\", \"Dodge Ram Pickup 3500 Crew Cab 2010\",\n",
    "        \"Dodge Ram Pickup 3500 Quad Cab 2009\", \"Dodge Sprinter Cargo Van 2009\", \"Dodge Journey SUV 2012\",\n",
    "        \"Dodge Dakota Crew Cab 2010\", \"Dodge Dakota Club Cab 2007\", \"Dodge Magnum Wagon 2008\",\n",
    "        \"Dodge Challenger SRT8 2011\", \"Dodge Durango SUV 2012\", \"Dodge Durango SUV 2007\",\n",
    "        \"Dodge Charger Sedan 2012\", \"Dodge Charger SRT-8 2009\", \"Eagle Talon Hatchback 1998\",\n",
    "        \"FIAT 500 Abarth 2012\", \"FIAT 500 Convertible 2012\", \"Ferrari FF Coupe 2012\",\n",
    "        \"Ferrari California Convertible 2012\", \"Ferrari 458 Italia Convertible 2012\", \"Ferrari 458 Italia Coupe 2012\",\n",
    "        \"Fisker Karma Sedan 2012\", \"Ford F-450 Super Duty Crew Cab 2012\", \"Ford Mustang Convertible 2007\",\n",
    "        \"Ford Freestar Minivan 2007\", \"Ford Expedition EL SUV 2009\", \"Ford Edge SUV 2012\",\n",
    "        \"Ford Ranger SuperCab 2011\", \"Ford GT Coupe 2006\", \"Ford F-150 Regular Cab 2012\",\n",
    "        \"Ford F-150 Regular Cab 2007\", \"Ford Focus Sedan 2007\", \"Ford E-Series Wagon Van 2012\",\n",
    "        \"Ford Fiesta Sedan 2012\", \"GMC Terrain SUV 2012\", \"GMC Savana Van 2012\",\n",
    "        \"GMC Yukon Hybrid SUV 2012\", \"GMC Acadia SUV 2012\", \"GMC Canyon Extended Cab 2012\",\n",
    "        \"Geo Metro Convertible 1993\", \"HUMMER H3T Crew Cab 2010\", \"HUMMER H2 SUT Crew Cab 2009\",\n",
    "        \"Honda Odyssey Minivan 2012\", \"Honda Odyssey Minivan 2007\", \"Honda Accord Coupe 2012\",\n",
    "        \"Honda Accord Sedan 2012\", \"Hyundai Veloster Hatchback 2012\", \"Hyundai Santa Fe SUV 2012\",\n",
    "        \"Hyundai Tucson SUV 2012\", \"Hyundai Veracruz SUV 2012\", \"Hyundai Sonata Hybrid Sedan 2012\",\n",
    "        \"Hyundai Elantra Sedan 2007\", \"Hyundai Accent Sedan 2012\", \"Hyundai Elantra Touring Hatchback 2012\",\n",
    "        \"Hyundai Sonata Sedan 2012\", \"Infiniti G Coupe IPL 2012\", \"Infiniti QX56 SUV 2011\",\n",
    "        \"Isuzu Ascender SUV 2008\", \"Jaguar XK XKR 2012\", \"Jeep Patriot SUV 2012\",\n",
    "        \"Jeep Wrangler SUV 2012\", \"Jeep Liberty SUV 2012\", \"Jeep Grand Cherokee SUV 2012\",\n",
    "        \"Jeep Compass SUV 2012\", \"Lamborghini Reventon Coupe 2008\", \"Lamborghini Aventador Coupe 2012\",\n",
    "        \"Lamborghini Gallardo LP 570-4 Superleggera 2012\", \"Lamborghini Diablo Coupe 2001\",\n",
    "        \"Land Rover Range Rover SUV 2012\", \"Land Rover LR2 SUV 2012\", \"Lincoln Town Car Sedan 2011\",\n",
    "        \"MINI Cooper Roadster Convertible 2012\", \"Maybach Landaulet Convertible 2012\", \"Mazda Tribute SUV 2011\",\n",
    "        \"McLaren MP4-12C Coupe 2012\", \"Mercedes-Benz 300-Class Convertible 1993\", \"Mercedes-Benz C-Class Sedan 2012\",\n",
    "        \"Mercedes-Benz SL-Class Coupe 2009\", \"Mercedes-Benz E-Class Sedan 2012\", \"Mercedes-Benz S-Class Sedan 2012\",\n",
    "        \"Mercedes-Benz Sprinter Van 2012\", \"Mitsubishi Lancer Evolution 2004\", \"Nissan Leaf Hatchback 2012\",\n",
    "        \"Nissan NV200 Minivan 2013\", \"Nissan Juke Hatchback 2012\", \"Nissan 240SX Coupe 1998\",\n",
    "        \"Plymouth Neon Coupe 1999\", \"Porsche Panamera Sedan 2012\", \"Ram C/V Cargo Van Minivan 2012\",\n",
    "        \"Rolls-Royce Phantom Drophead Coupe Convertible 2012\", \"Rolls-Royce Ghost Sedan 2012\",\n",
    "        \"Rolls-Royce Phantom Sedan 2012\", \"Scion xD Hatchback 2012\", \"Spyker C8 Convertible 2009\",\n",
    "        \"Spyker C8 Coupe 2009\", \"Suzuki Aerio Sedan 2007\", \"Suzuki Kizashi Sedan 2012\",\n",
    "        \"Suzuki SX4 Hatchback 2012\", \"Suzuki SX4 Sedan 2012\", \"Tesla Model S Sedan 2012\",\n",
    "        \"Toyota Sequoia SUV 2012\", \"Toyota Camry Sedan 2012\", \"Toyota Corolla Sedan 2012\",\n",
    "        \"Toyota 4Runner SUV 2012\", \"Volkswagen Golf Hatchback 2012\", \"Volkswagen Golf Hatchback 1991\",\n",
    "        \"Volkswagen Beetle Hatchback 2012\", \"Volvo C30 Hatchbook 2012\", \"Volvo 240 Sedan 1993\",\n",
    "        \"Volvo XC90 SUV 2007\", \"smart fortwo Convertible 2012\"\n",
    "    ]\n",
    "    \n",
    "    # Create class mappings\n",
    "    class_to_index = {cls: idx for idx, cls in enumerate(car_classes)}\n",
    "    index_to_class = {idx: cls for idx, cls in enumerate(car_classes)}\n",
    "    \n",
    "    return car_classes, class_to_index, index_to_class\n",
    "\n",
    "# Utilize detected dataset paths and setup metadata\n",
    "print(f\"\\nğŸ”§ UTILIZING DETECTED DATASET STRUCTURE...\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Check if dataset was properly detected and organized\n",
    "if 'DATASET_READY' in globals() and DATASET_READY:\n",
    "    print(f\"âœ… Dataset ready for use!\")\n",
    "    print(f\"ğŸ“ Train directory: {TRAIN_DIR}\")\n",
    "    print(f\"ğŸ“ Test directory: {TEST_DIR}\")\n",
    "    \n",
    "    # Use the detected paths\n",
    "    train_dir = TRAIN_DIR\n",
    "    test_dir = TEST_DIR\n",
    "    \n",
    "    # Get actual class names from the organized dataset\n",
    "    actual_classes = [d.name for d in train_dir.iterdir() if d.is_dir()]\n",
    "    actual_classes.sort()  # Sort for consistency\n",
    "    \n",
    "    print(f\"ğŸ“Š Detected {len(actual_classes)} classes from dataset structure\")\n",
    "    print(f\"ğŸ·ï¸ Sample classes: {actual_classes[:5]}\")\n",
    "    \n",
    "    # Update NUM_CLASSES to match actual dataset\n",
    "    NUM_CLASSES = len(actual_classes)\n",
    "    \n",
    "    # Create class mappings from actual dataset structure\n",
    "    class_to_index = {cls: idx for idx, cls in enumerate(actual_classes)}\n",
    "    index_to_class = {idx: cls for idx, cls in enumerate(actual_classes)}\n",
    "    car_classes = actual_classes\n",
    "    \n",
    "else:\n",
    "    print(f\"âš ï¸ Dataset not properly detected, using fallback metadata...\")\n",
    "    \n",
    "    # Fallback to predefined Stanford Cars class list\n",
    "    car_classes, class_to_index, index_to_class = load_stanford_cars_metadata()\n",
    "    NUM_CLASSES = len(car_classes)  # 196 classes for Stanford Cars\n",
    "    \n",
    "    # Set fallback paths\n",
    "    train_dir = Path(\"data/train\")\n",
    "    test_dir = Path(\"data/test\")\n",
    "    \n",
    "    print(f\"ğŸ“Š Using predefined {NUM_CLASSES} Stanford Cars classes\")\n",
    "    print(f\"ğŸ·ï¸ Sample classes: {car_classes[:5]}\")\n",
    "\n",
    "# Dataset configuration\n",
    "IMG_SIZE = (224, 224)  # Standard input size for ResNet50\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 20  # Training epochs\n",
    "\n",
    "print(f\"\\nğŸ“ˆ FINAL DATASET CONFIGURATION:\")\n",
    "print(f\"   Number of classes: {NUM_CLASSES}\")\n",
    "print(f\"   Image size: {IMG_SIZE}\")\n",
    "print(f\"   Batch size: {BATCH_SIZE}\")\n",
    "print(f\"   Training epochs: {EPOCHS}\")\n",
    "print(f\"   Train directory: {train_dir}\")\n",
    "print(f\"   Test directory: {test_dir}\")\n",
    "\n",
    "# Verify paths exist\n",
    "if train_dir.exists():\n",
    "    train_class_count = len([d for d in train_dir.iterdir() if d.is_dir()])\n",
    "    train_image_count = sum(len([f for f in class_dir.iterdir() if f.suffix.lower() in ['.jpg', '.jpeg', '.png']]) \n",
    "                           for class_dir in train_dir.iterdir() if class_dir.is_dir())\n",
    "    print(f\"   âœ… Train directory: {train_class_count} classes, {train_image_count} images\")\n",
    "else:\n",
    "    print(f\"   âŒ Train directory not found: {train_dir}\")\n",
    "\n",
    "if test_dir.exists():\n",
    "    test_class_count = len([d for d in test_dir.iterdir() if d.is_dir()])\n",
    "    test_image_count = sum(len([f for f in class_dir.iterdir() if f.suffix.lower() in ['.jpg', '.jpeg', '.png']]) \n",
    "                          for class_dir in test_dir.iterdir() if class_dir.is_dir())\n",
    "    print(f\"   âœ… Test directory: {test_class_count} classes, {test_image_count} images\")\n",
    "else:\n",
    "    print(f\"   âš ï¸ Test directory not found: {test_dir}\")\n",
    "\n",
    "# Save class mapping for API and deployment use\n",
    "print(f\"\\nğŸ’¾ Saving class mapping...\")\n",
    "class_mapping = {\n",
    "    'class_to_index': class_to_index,\n",
    "    'index_to_class': index_to_class,\n",
    "    'num_classes': NUM_CLASSES,\n",
    "    'class_names': car_classes\n",
    "}\n",
    "\n",
    "import json\n",
    "with open('class_mapping.json', 'w') as f:\n",
    "    json.dump(class_mapping, f, indent=2)\n",
    "\n",
    "print(f\"âœ… Class mapping saved to 'class_mapping.json'\")\n",
    "print(f\"ğŸ“‹ Mapping contains {len(class_mapping['class_names'])} classes\")\n",
    "\n",
    "# Display final status\n",
    "print(f\"\\nğŸ¯ DATASET SETUP STATUS:\")\n",
    "if 'DATASET_READY' in globals() and DATASET_READY and train_dir.exists():\n",
    "    print(\"âœ… Dataset is ready for model training!\")\n",
    "    print(\"ğŸš€ You can proceed to the next cells for data preprocessing and model training\")\n",
    "else:\n",
    "    print(\"âš ï¸ Dataset setup incomplete\")\n",
    "    print(\"ğŸ’¡ Please ensure dataset is properly downloaded and organized\")\n",
    "\n",
    "print(\"=\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a046943",
   "metadata": {},
   "source": [
    "# 3. Model Architecture\n",
    "\n",
    "## Objective\n",
    "Build a deep learning model using transfer learning with a pre-trained backbone for car classification.\n",
    "\n",
    "**Thought Process: For 196 classes, transfer learning is efficient. ResNet50 is chosen for its proven performance on ImageNet, suitable for 224x224 inputs, balancing accuracy and computation. We'll freeze early layers initially, fine-tune later, assuming sufficient data for adaptation, and use dropout to prevent overfitting.**\n",
    "\n",
    "## Design Decisions\n",
    "**Backbone**: ResNet50 pre-trained on ImageNet\n",
    "- Proven architecture for image classification\n",
    "- Good balance between accuracy and computational efficiency\n",
    "- 224x224 input size standard\n",
    "\n",
    "**Transfer Learning Strategy**: \n",
    "- Freeze the convolutional base initially\n",
    "- Replace the top classification layer\n",
    "- Fine-tune the top layers after initial training\n",
    "\n",
    "**Architecture Assumptions**:\n",
    "- Input images: 224x224x3 (RGB)\n",
    "- Output: 196 classes (Stanford Cars Dataset)\n",
    "- Global Average Pooling to reduce parameters\n",
    "- Dropout for regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "036c3268",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ—ï¸ Building Enhanced Car Classification Model...\n",
      "ğŸ“Š Base model layers: 175\n",
      "ğŸ”’ Frozen layers: 155\n",
      "ğŸ”“ Trainable layers: 20\n",
      "âœ… Model compiled successfully!\n",
      "\n",
      "ğŸ“‹ Model Summary:\n",
      "ğŸ“Š Base model layers: 175\n",
      "ğŸ”’ Frozen layers: 155\n",
      "ğŸ”“ Trainable layers: 20\n",
      "âœ… Model compiled successfully!\n",
      "\n",
      "ğŸ“‹ Model Summary:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ<span style=\"font-weight: bold\"> Layer (type)                    </span>â”ƒ<span style=\"font-weight: bold\"> Output Shape           </span>â”ƒ<span style=\"font-weight: bold\">       Param # </span>â”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚ resnet50 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)           â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)     â”‚    <span style=\"color: #00af00; text-decoration-color: #00af00\">23,587,712</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ global_average_pooling2d        â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)           â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)        â”‚                        â”‚               â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)           â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            â”‚     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,049,088</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ batch_normalization             â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            â”‚         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            â”‚                        â”‚               â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            â”‚       <span style=\"color: #00af00; text-decoration-color: #00af00\">131,328</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">196</span>)            â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">50,372</span> â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
       "</pre>\n"
      ],
      "text/plain": [
       "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚ resnet50 (\u001b[38;5;33mFunctional\u001b[0m)           â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m2048\u001b[0m)     â”‚    \u001b[38;5;34m23,587,712\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ global_average_pooling2d        â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2048\u001b[0m)           â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”‚ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)        â”‚                        â”‚               â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout (\u001b[38;5;33mDropout\u001b[0m)               â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2048\u001b[0m)           â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense (\u001b[38;5;33mDense\u001b[0m)                   â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            â”‚     \u001b[38;5;34m1,049,088\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ batch_normalization             â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            â”‚         \u001b[38;5;34m2,048\u001b[0m â”‚\n",
       "â”‚ (\u001b[38;5;33mBatchNormalization\u001b[0m)            â”‚                        â”‚               â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            â”‚       \u001b[38;5;34m131,328\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m196\u001b[0m)            â”‚        \u001b[38;5;34m50,372\u001b[0m â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">24,820,548</span> (94.68 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m24,820,548\u001b[0m (94.68 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">10,163,140</span> (38.77 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m10,163,140\u001b[0m (38.77 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">14,657,408</span> (55.91 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m14,657,408\u001b[0m (55.91 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âš™ï¸ Training callbacks configured:\n",
      "   â€¢ EarlyStopping (patience=10, restore_best_weights=True)\n",
      "   â€¢ ReduceLROnPlateau (factor=0.2, patience=5)\n",
      "   â€¢ ModelCheckpoint (best_car_model.keras, save_format='keras')\n",
      "\n",
      "ğŸ¯ Model ready for training on 196 car classes!\n",
      "ğŸ“Š Total parameters: 24,820,548\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
    "from tensorflow.keras.regularizers import l2\n",
    "def create_car_classification_model():\n",
    "    \"\"\"\n",
    "    Create an improved CNN model for car classification using TFâ€¯2.19 best practices.\n",
    "    \"\"\"\n",
    "    print(\"ğŸ—ï¸ Building Enhanced Car Classification Model...\")\n",
    "\n",
    "    # 1) Base pretrained backbone\n",
    "    base_model = ResNet50(\n",
    "        weights='imagenet',\n",
    "        include_top=False,\n",
    "        input_shape=(*IMG_SIZE, 3)\n",
    "    )\n",
    "\n",
    "    # 2) Freeze early layers, fineâ€‘tune last 20\n",
    "    for layer in base_model.layers[:-20]:\n",
    "        layer.trainable = False\n",
    "\n",
    "    print(f\"ğŸ“Š Base model layers: {len(base_model.layers)}\")\n",
    "    print(f\"ğŸ”’ Frozen layers: {len([l for l in base_model.layers if not l.trainable])}\")\n",
    "    print(f\"ğŸ”“ Trainable layers: {len([l for l in base_model.layers if l.trainable])}\")\n",
    "\n",
    "    # 3) Build your head\n",
    "    model = Sequential([\n",
    "        base_model,\n",
    "        layers.GlobalAveragePooling2D(),\n",
    "        layers.Dropout(0.3),\n",
    "        layers.Dense(512, activation='relu'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Dropout(0.5),\n",
    "        layers.Dense(256, activation='relu'),\n",
    "        layers.Dropout(0.3),\n",
    "        layers.Dense(\n",
    "            NUM_CLASSES,\n",
    "            activation='softmax',\n",
    "            kernel_regularizer=l2(0.01)\n",
    "        )\n",
    "    ])\n",
    "\n",
    "    # 4) Compile with modern metrics API\n",
    "    model.compile(\n",
    "        optimizer=Adam(learning_rate=1e-4),\n",
    "        loss='categorical_crossentropy',\n",
    "        metrics=[\n",
    "            'accuracy',\n",
    "            tf.keras.metrics.TopKCategoricalAccuracy(k=5, name='top_5_accuracy')\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    print(\"âœ… Model compiled successfully!\")\n",
    "    print(\"\\nğŸ“‹ Model Summary:\")\n",
    "    model.summary()\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def setup_training_callbacks():\n",
    "    \"\"\"\n",
    "    Set up callbacks for TFâ€¯2.19 training:\n",
    "      - EarlyStopping\n",
    "      - ReduceLROnPlateau\n",
    "      - ModelCheckpoint in SavedModel/Keras format\n",
    "    \"\"\"\n",
    "    callbacks = [\n",
    "        EarlyStopping(\n",
    "            monitor='val_accuracy',\n",
    "            patience=10,\n",
    "            restore_best_weights=True,\n",
    "            verbose=1\n",
    "        ),\n",
    "\n",
    "        ReduceLROnPlateau(\n",
    "            monitor='val_loss',\n",
    "            factor=0.2,\n",
    "            patience=5,\n",
    "            min_lr=1e-7,\n",
    "            verbose=1\n",
    "        ),\n",
    "\n",
    "        ModelCheckpoint(\n",
    "            'best_car_model.keras',        # .keras = SavedModel/Keras v3 format\n",
    "            monitor='val_accuracy',\n",
    "            save_best_only=True,\n",
    "            verbose=1\n",
    "        )\n",
    "    ]\n",
    "\n",
    "    print(\"âš™ï¸ Training callbacks configured:\")\n",
    "    print(\"   â€¢ EarlyStopping (patience=10, restore_best_weights=True)\")\n",
    "    print(\"   â€¢ ReduceLROnPlateau (factor=0.2, patience=5)\")\n",
    "    print(\"   â€¢ ModelCheckpoint (best_car_model.keras, save_format='keras')\")\n",
    "\n",
    "    return callbacks\n",
    "\n",
    "# Usage\n",
    "model = create_car_classification_model()\n",
    "callbacks = setup_training_callbacks()\n",
    "\n",
    "print(f\"\\nğŸ¯ Model ready for training on {NUM_CLASSES} car classes!\")\n",
    "print(f\"ğŸ“Š Total parameters: {model.count_params():,}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34133373",
   "metadata": {},
   "source": [
    "# 4. Training Pipeline\n",
    "\n",
    "## Objective\n",
    "Train the model with transfer learning approach and monitor performance metrics.\n",
    "\n",
    "**Thought Process: We'll train in phases: first, freeze the backbone for quick adaptation (10-15 epochs), then fine-tune top layers (10-20 epochs) with lower learning rate. Batch size 32 balances memory and speed, Adam at 1e-4 is standard for fine-tuning, and callbacks prevent overfitting, ensuring robust training.**\n",
    "\n",
    "## Training Strategy\n",
    "1. **Phase 1**: Train with frozen backbone (feature extraction)\n",
    "   - Quick initial training to adapt the classifier head\n",
    "   - 10-15 epochs with higher learning rate\n",
    "\n",
    "2. **Phase 2**: Fine-tuning (optional)\n",
    "   - Unfreeze top layers of the backbone\n",
    "   - Lower learning rate for fine-tuning\n",
    "   - Additional 10-20 epochs\n",
    "\n",
    "## Callbacks and Monitoring\n",
    "- **EarlyStopping**: Prevent overfitting\n",
    "- **ReduceLROnPlateau**: Adaptive learning rate\n",
    "- **ModelCheckpoint**: Save best model weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a1e0f87a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” CHECKING FOR EXISTING TRAINED MODEL...\n",
      "=============================================\n",
      "ğŸ“‹ No existing model found\n",
      "ğŸš€ Will proceed with training new model\n",
      "\n",
      "==================================================\n",
      "ğŸš€ STARTING TRAINING WITH TENSORFLOW 2.19\n",
      "==================================================\n",
      "ğŸ”§ Applying TensorFlow 2.19 compatibility fixes...\n",
      "âœ… Model fixed for TensorFlow 2.19 compatibility\n",
      "ğŸ“ Setting up datasets...\n",
      "Found 8144 files belonging to 196 classes.\n",
      "Using 6516 files for training.\n",
      "Found 8144 files belonging to 196 classes.\n",
      "Using 6516 files for training.\n",
      "Found 8144 files belonging to 196 classes.\n",
      "Using 1628 files for validation.\n",
      "Found 8144 files belonging to 196 classes.\n",
      "Using 1628 files for validation.\n",
      "Found 8041 files belonging to 196 classes.\n",
      "Found 8041 files belonging to 196 classes.\n",
      "âœ… Datasets ready: train=204 batches, val=51 batches, test=252 batches\n",
      "ğŸ¯ Using real Stanford Cars dataset\n",
      "\n",
      "ğŸ‹ï¸ STARTING TRAINING...\n",
      "==============================\n",
      "ğŸ“Š Training on 196 car classes\n",
      "ğŸ¯ Max epochs: 20 (early stopping enabled)\n",
      "Epoch 1/20\n",
      "âœ… Datasets ready: train=204 batches, val=51 batches, test=252 batches\n",
      "ğŸ¯ Using real Stanford Cars dataset\n",
      "\n",
      "ğŸ‹ï¸ STARTING TRAINING...\n",
      "==============================\n",
      "ğŸ“Š Training on 196 car classes\n",
      "ğŸ¯ Max epochs: 20 (early stopping enabled)\n",
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1753295408.066386   15978 service.cc:152] XLA service 0x758b74018b60 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1753295408.066509   15978 service.cc:160]   StreamExecutor device (0): NVIDIA GeForce RTX 4060, Compute Capability 8.9\n",
      "I0000 00:00:1753295409.181528   15978 cuda_dnn.cc:529] Loaded cuDNN version 91100\n",
      "I0000 00:00:1753295409.181528   15978 cuda_dnn.cc:529] Loaded cuDNN version 91100\n",
      "I0000 00:00:1753295420.094319   15978 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "I0000 00:00:1753295420.094319   15978 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m203/204\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - accuracy: 0.0083 - loss: 8.2434 - top_5_accuracy: 0.0340\n",
      "Epoch 1: val_accuracy improved from -inf to 0.02334, saving model to best_car_model.keras\n",
      "\n",
      "Epoch 1: val_accuracy improved from -inf to 0.02334, saving model to best_car_model.keras\n",
      "\u001b[1m204/204\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 132ms/step - accuracy: 0.0083 - loss: 8.2413 - top_5_accuracy: 0.0340 - val_accuracy: 0.0233 - val_loss: 7.1399 - val_top_5_accuracy: 0.1014 - learning_rate: 1.0000e-04\n",
      "Epoch 2/20\n",
      "\u001b[1m204/204\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 132ms/step - accuracy: 0.0083 - loss: 8.2413 - top_5_accuracy: 0.0340 - val_accuracy: 0.0233 - val_loss: 7.1399 - val_top_5_accuracy: 0.1014 - learning_rate: 1.0000e-04\n",
      "Epoch 2/20\n",
      "\u001b[1m204/204\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.0225 - loss: 7.3560 - top_5_accuracy: 0.0877\n",
      "Epoch 2: val_accuracy improved from 0.02334 to 0.07801, saving model to best_car_model.keras\n",
      "\n",
      "Epoch 2: val_accuracy improved from 0.02334 to 0.07801, saving model to best_car_model.keras\n",
      "\u001b[1m204/204\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 37ms/step - accuracy: 0.0225 - loss: 7.3555 - top_5_accuracy: 0.0877 - val_accuracy: 0.0780 - val_loss: 6.5868 - val_top_5_accuracy: 0.2273 - learning_rate: 1.0000e-04\n",
      "Epoch 3/20\n",
      "\u001b[1m204/204\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 37ms/step - accuracy: 0.0225 - loss: 7.3555 - top_5_accuracy: 0.0877 - val_accuracy: 0.0780 - val_loss: 6.5868 - val_top_5_accuracy: 0.2273 - learning_rate: 1.0000e-04\n",
      "Epoch 3/20\n",
      "\u001b[1m203/204\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.0562 - loss: 6.7349 - top_5_accuracy: 0.1762\n",
      "Epoch 3: val_accuracy improved from 0.07801 to 0.12531, saving model to best_car_model.keras\n",
      "\n",
      "Epoch 3: val_accuracy improved from 0.07801 to 0.12531, saving model to best_car_model.keras\n",
      "\u001b[1m204/204\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 30ms/step - accuracy: 0.0562 - loss: 6.7340 - top_5_accuracy: 0.1763 - val_accuracy: 0.1253 - val_loss: 6.0984 - val_top_5_accuracy: 0.3366 - learning_rate: 1.0000e-04\n",
      "Epoch 4/20\n",
      "\u001b[1m204/204\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 30ms/step - accuracy: 0.0562 - loss: 6.7340 - top_5_accuracy: 0.1763 - val_accuracy: 0.1253 - val_loss: 6.0984 - val_top_5_accuracy: 0.3366 - learning_rate: 1.0000e-04\n",
      "Epoch 4/20\n",
      "\u001b[1m204/204\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.1072 - loss: 6.1281 - top_5_accuracy: 0.2709\n",
      "Epoch 4: val_accuracy improved from 0.12531 to 0.16953, saving model to best_car_model.keras\n",
      "\n",
      "Epoch 4: val_accuracy improved from 0.12531 to 0.16953, saving model to best_car_model.keras\n",
      "\u001b[1m204/204\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 38ms/step - accuracy: 0.1072 - loss: 6.1277 - top_5_accuracy: 0.2710 - val_accuracy: 0.1695 - val_loss: 5.6595 - val_top_5_accuracy: 0.4189 - learning_rate: 1.0000e-04\n",
      "Epoch 5/20\n",
      "\u001b[1m204/204\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 38ms/step - accuracy: 0.1072 - loss: 6.1277 - top_5_accuracy: 0.2710 - val_accuracy: 0.1695 - val_loss: 5.6595 - val_top_5_accuracy: 0.4189 - learning_rate: 1.0000e-04\n",
      "Epoch 5/20\n",
      "\u001b[1m204/204\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.1624 - loss: 5.5700 - top_5_accuracy: 0.3920\n",
      "Epoch 5: val_accuracy improved from 0.16953 to 0.22604, saving model to best_car_model.keras\n",
      "\n",
      "Epoch 5: val_accuracy improved from 0.16953 to 0.22604, saving model to best_car_model.keras\n",
      "\u001b[1m204/204\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 37ms/step - accuracy: 0.1625 - loss: 5.5697 - top_5_accuracy: 0.3920 - val_accuracy: 0.2260 - val_loss: 5.2972 - val_top_5_accuracy: 0.4889 - learning_rate: 1.0000e-04\n",
      "Epoch 6/20\n",
      "\u001b[1m204/204\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 37ms/step - accuracy: 0.1625 - loss: 5.5697 - top_5_accuracy: 0.3920 - val_accuracy: 0.2260 - val_loss: 5.2972 - val_top_5_accuracy: 0.4889 - learning_rate: 1.0000e-04\n",
      "Epoch 6/20\n",
      "\u001b[1m204/204\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.2480 - loss: 5.0610 - top_5_accuracy: 0.4959\n",
      "Epoch 6: val_accuracy improved from 0.22604 to 0.25737, saving model to best_car_model.keras\n",
      "\n",
      "Epoch 6: val_accuracy improved from 0.22604 to 0.25737, saving model to best_car_model.keras\n",
      "\u001b[1m204/204\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 37ms/step - accuracy: 0.2480 - loss: 5.0606 - top_5_accuracy: 0.4960 - val_accuracy: 0.2574 - val_loss: 4.9328 - val_top_5_accuracy: 0.5473 - learning_rate: 1.0000e-04\n",
      "Epoch 7/20\n",
      "\u001b[1m204/204\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 37ms/step - accuracy: 0.2480 - loss: 5.0606 - top_5_accuracy: 0.4960 - val_accuracy: 0.2574 - val_loss: 4.9328 - val_top_5_accuracy: 0.5473 - learning_rate: 1.0000e-04\n",
      "Epoch 7/20\n",
      "\u001b[1m204/204\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.3344 - loss: 4.5437 - top_5_accuracy: 0.6217\n",
      "Epoch 7: val_accuracy improved from 0.25737 to 0.29975, saving model to best_car_model.keras\n",
      "\n",
      "Epoch 7: val_accuracy improved from 0.25737 to 0.29975, saving model to best_car_model.keras\n",
      "\u001b[1m204/204\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 31ms/step - accuracy: 0.3345 - loss: 4.5433 - top_5_accuracy: 0.6218 - val_accuracy: 0.2998 - val_loss: 4.5903 - val_top_5_accuracy: 0.6081 - learning_rate: 1.0000e-04\n",
      "Epoch 8/20\n",
      "\u001b[1m204/204\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 31ms/step - accuracy: 0.3345 - loss: 4.5433 - top_5_accuracy: 0.6218 - val_accuracy: 0.2998 - val_loss: 4.5903 - val_top_5_accuracy: 0.6081 - learning_rate: 1.0000e-04\n",
      "Epoch 8/20\n",
      "\u001b[1m204/204\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.4377 - loss: 3.9642 - top_5_accuracy: 0.7431\n",
      "Epoch 8: val_accuracy improved from 0.29975 to 0.34459, saving model to best_car_model.keras\n",
      "\n",
      "Epoch 8: val_accuracy improved from 0.29975 to 0.34459, saving model to best_car_model.keras\n",
      "\u001b[1m204/204\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 37ms/step - accuracy: 0.4377 - loss: 3.9640 - top_5_accuracy: 0.7431 - val_accuracy: 0.3446 - val_loss: 4.3298 - val_top_5_accuracy: 0.6327 - learning_rate: 1.0000e-04\n",
      "Epoch 9/20\n",
      "\u001b[1m204/204\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 37ms/step - accuracy: 0.4377 - loss: 3.9640 - top_5_accuracy: 0.7431 - val_accuracy: 0.3446 - val_loss: 4.3298 - val_top_5_accuracy: 0.6327 - learning_rate: 1.0000e-04\n",
      "Epoch 9/20\n",
      "\u001b[1m203/204\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.5450 - loss: 3.4755 - top_5_accuracy: 0.8356\n",
      "Epoch 9: val_accuracy improved from 0.34459 to 0.36916, saving model to best_car_model.keras\n",
      "\n",
      "Epoch 9: val_accuracy improved from 0.34459 to 0.36916, saving model to best_car_model.keras\n",
      "\u001b[1m204/204\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 40ms/step - accuracy: 0.5451 - loss: 3.4749 - top_5_accuracy: 0.8356 - val_accuracy: 0.3692 - val_loss: 4.0463 - val_top_5_accuracy: 0.6873 - learning_rate: 1.0000e-04\n",
      "Epoch 10/20\n",
      "\u001b[1m204/204\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 40ms/step - accuracy: 0.5451 - loss: 3.4749 - top_5_accuracy: 0.8356 - val_accuracy: 0.3692 - val_loss: 4.0463 - val_top_5_accuracy: 0.6873 - learning_rate: 1.0000e-04\n",
      "Epoch 10/20\n",
      "\u001b[1m203/204\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.6589 - loss: 2.9748 - top_5_accuracy: 0.9097\n",
      "Epoch 10: val_accuracy improved from 0.36916 to 0.40848, saving model to best_car_model.keras\n",
      "\n",
      "Epoch 10: val_accuracy improved from 0.36916 to 0.40848, saving model to best_car_model.keras\n",
      "\u001b[1m204/204\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 38ms/step - accuracy: 0.6589 - loss: 2.9744 - top_5_accuracy: 0.9097 - val_accuracy: 0.4085 - val_loss: 3.9104 - val_top_5_accuracy: 0.7027 - learning_rate: 1.0000e-04\n",
      "Epoch 11/20\n",
      "\u001b[1m204/204\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 38ms/step - accuracy: 0.6589 - loss: 2.9744 - top_5_accuracy: 0.9097 - val_accuracy: 0.4085 - val_loss: 3.9104 - val_top_5_accuracy: 0.7027 - learning_rate: 1.0000e-04\n",
      "Epoch 11/20\n",
      "\u001b[1m204/204\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.7507 - loss: 2.5587 - top_5_accuracy: 0.9548\n",
      "Epoch 11: val_accuracy improved from 0.40848 to 0.43366, saving model to best_car_model.keras\n",
      "\n",
      "Epoch 11: val_accuracy improved from 0.40848 to 0.43366, saving model to best_car_model.keras\n",
      "\u001b[1m204/204\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 30ms/step - accuracy: 0.7507 - loss: 2.5585 - top_5_accuracy: 0.9548 - val_accuracy: 0.4337 - val_loss: 3.7198 - val_top_5_accuracy: 0.7144 - learning_rate: 1.0000e-04\n",
      "Epoch 12/20\n",
      "\u001b[1m204/204\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 30ms/step - accuracy: 0.7507 - loss: 2.5585 - top_5_accuracy: 0.9548 - val_accuracy: 0.4337 - val_loss: 3.7198 - val_top_5_accuracy: 0.7144 - learning_rate: 1.0000e-04\n",
      "Epoch 12/20\n",
      "\u001b[1m204/204\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.8478 - loss: 2.1602 - top_5_accuracy: 0.9824\n",
      "Epoch 12: val_accuracy improved from 0.43366 to 0.45762, saving model to best_car_model.keras\n",
      "\n",
      "Epoch 12: val_accuracy improved from 0.43366 to 0.45762, saving model to best_car_model.keras\n",
      "\u001b[1m204/204\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 36ms/step - accuracy: 0.8478 - loss: 2.1601 - top_5_accuracy: 0.9824 - val_accuracy: 0.4576 - val_loss: 3.5675 - val_top_5_accuracy: 0.7426 - learning_rate: 1.0000e-04\n",
      "Epoch 13/20\n",
      "\u001b[1m204/204\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 36ms/step - accuracy: 0.8478 - loss: 2.1601 - top_5_accuracy: 0.9824 - val_accuracy: 0.4576 - val_loss: 3.5675 - val_top_5_accuracy: 0.7426 - learning_rate: 1.0000e-04\n",
      "Epoch 13/20\n",
      "\u001b[1m204/204\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9023 - loss: 1.8719 - top_5_accuracy: 0.9905\n",
      "Epoch 13: val_accuracy did not improve from 0.45762\n",
      "\u001b[1m204/204\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 33ms/step - accuracy: 0.9023 - loss: 1.8717 - top_5_accuracy: 0.9905 - val_accuracy: 0.4527 - val_loss: 3.4540 - val_top_5_accuracy: 0.7396 - learning_rate: 1.0000e-04\n",
      "Epoch 14/20\n",
      "\n",
      "Epoch 13: val_accuracy did not improve from 0.45762\n",
      "\u001b[1m204/204\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 33ms/step - accuracy: 0.9023 - loss: 1.8717 - top_5_accuracy: 0.9905 - val_accuracy: 0.4527 - val_loss: 3.4540 - val_top_5_accuracy: 0.7396 - learning_rate: 1.0000e-04\n",
      "Epoch 14/20\n",
      "\u001b[1m204/204\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9403 - loss: 1.6645 - top_5_accuracy: 0.9972\n",
      "Epoch 14: val_accuracy did not improve from 0.45762\n",
      "\u001b[1m204/204\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 34ms/step - accuracy: 0.9404 - loss: 1.6643 - top_5_accuracy: 0.9972 - val_accuracy: 0.4472 - val_loss: 3.3975 - val_top_5_accuracy: 0.7396 - learning_rate: 1.0000e-04\n",
      "Epoch 15/20\n",
      "\n",
      "Epoch 14: val_accuracy did not improve from 0.45762\n",
      "\u001b[1m204/204\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 34ms/step - accuracy: 0.9404 - loss: 1.6643 - top_5_accuracy: 0.9972 - val_accuracy: 0.4472 - val_loss: 3.3975 - val_top_5_accuracy: 0.7396 - learning_rate: 1.0000e-04\n",
      "Epoch 15/20\n",
      "\u001b[1m204/204\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9638 - loss: 1.4731 - top_5_accuracy: 0.9995\n",
      "Epoch 15: val_accuracy did not improve from 0.45762\n",
      "\u001b[1m204/204\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 34ms/step - accuracy: 0.9638 - loss: 1.4730 - top_5_accuracy: 0.9995 - val_accuracy: 0.4484 - val_loss: 3.3705 - val_top_5_accuracy: 0.7193 - learning_rate: 1.0000e-04\n",
      "Epoch 16/20\n",
      "\n",
      "Epoch 15: val_accuracy did not improve from 0.45762\n",
      "\u001b[1m204/204\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 34ms/step - accuracy: 0.9638 - loss: 1.4730 - top_5_accuracy: 0.9995 - val_accuracy: 0.4484 - val_loss: 3.3705 - val_top_5_accuracy: 0.7193 - learning_rate: 1.0000e-04\n",
      "Epoch 16/20\n",
      "\u001b[1m204/204\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9786 - loss: 1.3217 - top_5_accuracy: 0.9997\n",
      "Epoch 16: val_accuracy improved from 0.45762 to 0.47912, saving model to best_car_model.keras\n",
      "\n",
      "Epoch 16: val_accuracy improved from 0.45762 to 0.47912, saving model to best_car_model.keras\n",
      "\u001b[1m204/204\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 31ms/step - accuracy: 0.9786 - loss: 1.3216 - top_5_accuracy: 0.9997 - val_accuracy: 0.4791 - val_loss: 3.1674 - val_top_5_accuracy: 0.7475 - learning_rate: 1.0000e-04\n",
      "Epoch 17/20\n",
      "\u001b[1m204/204\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 31ms/step - accuracy: 0.9786 - loss: 1.3216 - top_5_accuracy: 0.9997 - val_accuracy: 0.4791 - val_loss: 3.1674 - val_top_5_accuracy: 0.7475 - learning_rate: 1.0000e-04\n",
      "Epoch 17/20\n",
      "\u001b[1m204/204\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9855 - loss: 1.2018 - top_5_accuracy: 0.9991\n",
      "Epoch 17: val_accuracy did not improve from 0.47912\n",
      "\u001b[1m204/204\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 33ms/step - accuracy: 0.9855 - loss: 1.2017 - top_5_accuracy: 0.9991 - val_accuracy: 0.4644 - val_loss: 3.1315 - val_top_5_accuracy: 0.7500 - learning_rate: 1.0000e-04\n",
      "Epoch 18/20\n",
      "\n",
      "Epoch 17: val_accuracy did not improve from 0.47912\n",
      "\u001b[1m204/204\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 33ms/step - accuracy: 0.9855 - loss: 1.2017 - top_5_accuracy: 0.9991 - val_accuracy: 0.4644 - val_loss: 3.1315 - val_top_5_accuracy: 0.7500 - learning_rate: 1.0000e-04\n",
      "Epoch 18/20\n",
      "\u001b[1m204/204\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9919 - loss: 1.0992 - top_5_accuracy: 0.9999\n",
      "Epoch 18: val_accuracy did not improve from 0.47912\n",
      "\u001b[1m204/204\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 33ms/step - accuracy: 0.9919 - loss: 1.0991 - top_5_accuracy: 0.9999 - val_accuracy: 0.4760 - val_loss: 3.0323 - val_top_5_accuracy: 0.7482 - learning_rate: 1.0000e-04\n",
      "Epoch 19/20\n",
      "\n",
      "Epoch 18: val_accuracy did not improve from 0.47912\n",
      "\u001b[1m204/204\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 33ms/step - accuracy: 0.9919 - loss: 1.0991 - top_5_accuracy: 0.9999 - val_accuracy: 0.4760 - val_loss: 3.0323 - val_top_5_accuracy: 0.7482 - learning_rate: 1.0000e-04\n",
      "Epoch 19/20\n",
      "\u001b[1m204/204\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9950 - loss: 1.0021 - top_5_accuracy: 1.0000\n",
      "Epoch 19: val_accuracy did not improve from 0.47912\n",
      "\u001b[1m204/204\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 34ms/step - accuracy: 0.9950 - loss: 1.0020 - top_5_accuracy: 1.0000 - val_accuracy: 0.4767 - val_loss: 2.9866 - val_top_5_accuracy: 0.7494 - learning_rate: 1.0000e-04\n",
      "Epoch 20/20\n",
      "\n",
      "Epoch 19: val_accuracy did not improve from 0.47912\n",
      "\u001b[1m204/204\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 34ms/step - accuracy: 0.9950 - loss: 1.0020 - top_5_accuracy: 1.0000 - val_accuracy: 0.4767 - val_loss: 2.9866 - val_top_5_accuracy: 0.7494 - learning_rate: 1.0000e-04\n",
      "Epoch 20/20\n",
      "\u001b[1m204/204\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.9952 - loss: 0.9294 - top_5_accuracy: 0.9999\n",
      "Epoch 20: val_accuracy did not improve from 0.47912\n",
      "\u001b[1m204/204\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 33ms/step - accuracy: 0.9952 - loss: 0.9293 - top_5_accuracy: 0.9999 - val_accuracy: 0.4699 - val_loss: 2.9374 - val_top_5_accuracy: 0.7396 - learning_rate: 1.0000e-04\n",
      "Restoring model weights from the end of the best epoch: 16.\n",
      "\n",
      "Epoch 20: val_accuracy did not improve from 0.47912\n",
      "\u001b[1m204/204\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 33ms/step - accuracy: 0.9952 - loss: 0.9293 - top_5_accuracy: 0.9999 - val_accuracy: 0.4699 - val_loss: 2.9374 - val_top_5_accuracy: 0.7396 - learning_rate: 1.0000e-04\n",
      "Restoring model weights from the end of the best epoch: 16.\n",
      "\n",
      "âœ… TRAINING COMPLETED!\n",
      "ğŸ“Š Training history saved to 'history' variable\n",
      "ğŸ’¾ Best model saved as 'best_car_model_EfficientNetB4.keras'\n",
      "ğŸ’¾ Saving training history to file...\n",
      "âœ… Training history saved as 'training_history.pkl'\n",
      "âœ… Training history also saved as 'training_history.json'\n",
      "\n",
      "ğŸ“‹ Final Status: Training Completed\n",
      "\n",
      "âœ… TRAINING COMPLETED!\n",
      "ğŸ“Š Training history saved to 'history' variable\n",
      "ğŸ’¾ Best model saved as 'best_car_model_EfficientNetB4.keras'\n",
      "ğŸ’¾ Saving training history to file...\n",
      "âœ… Training history saved as 'training_history.pkl'\n",
      "âœ… Training history also saved as 'training_history.json'\n",
      "\n",
      "ğŸ“‹ Final Status: Training Completed\n"
     ]
    }
   ],
   "source": [
    "# =======================================\n",
    "# ğŸš€ SMART TRAINING PIPELINE - TensorFlow 2.19\n",
    "# =======================================\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "print(\"ğŸ” CHECKING FOR EXISTING TRAINED MODEL...\")\n",
    "print(\"=\" * 45)\n",
    "\n",
    "# Check if trained model exists\n",
    "model_path = Path('best_car_model_EfficientNetB4.keras')\n",
    "if model_path.exists():\n",
    "    print(f\"âœ… Found existing trained model: {model_path}\")\n",
    "    print(f\"ğŸ“Š Model size: {model_path.stat().st_size / (1024*1024):.1f} MB\")\n",
    "    \n",
    "    try:\n",
    "        # Load the existing model\n",
    "        print(\"ğŸ”„ Loading pre-trained model...\")\n",
    "        model = tf.keras.models.load_model(str(model_path))\n",
    "        print(\"âœ… Pre-trained model loaded successfully!\")\n",
    "        print(f\"ğŸ“Š Model parameters: {model.count_params():,}\")\n",
    "        \n",
    "        # Verify model works (only if dataset is ready and val_ds exists)\n",
    "        print(\"ğŸ§ª Testing model...\")\n",
    "        if DATASET_READY and 'val_ds' in globals():\n",
    "            sample_batch = next(iter(val_ds.take(1)))\n",
    "            test_prediction = model.predict(sample_batch[0][:1], verbose=0)\n",
    "            print(f\"âœ… Model test successful - output shape: {test_prediction.shape}\")\n",
    "        else:\n",
    "            # Create a simple test with random data instead\n",
    "            test_input = tf.random.normal((1, 224, 224, 3))\n",
    "            test_prediction = model.predict(test_input, verbose=0)\n",
    "            print(f\"âœ… Model test successful - output shape: {test_prediction.shape}\")\n",
    "        \n",
    "        SKIP_TRAINING = True\n",
    "        print(\"\\nğŸ¯ TRAINING WILL BE SKIPPED - Using existing model\")\n",
    "        print(\"ğŸ’¡ To retrain, delete 'best_car_model_EfficientNetB4.keras' and rerun this cell\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Failed to load existing model: {e}\")\n",
    "        print(\"ğŸ”§ Will create and train new model instead...\")\n",
    "        SKIP_TRAINING = False\n",
    "\n",
    "else:\n",
    "    print(\"ğŸ“‹ No existing model found\")\n",
    "    print(\"ğŸš€ Will proceed with training new model\")\n",
    "    SKIP_TRAINING = False\n",
    "\n",
    "# =======================================\n",
    "# CONDITIONAL TRAINING LOGIC\n",
    "# =======================================\n",
    "\n",
    "if SKIP_TRAINING:\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"ğŸ”„ SKIPPING TRAINING - USING EXISTING MODEL\")\n",
    "    print(\"=\"*50)\n",
    "    print(f\"âœ… Model ready: {model.name}\")\n",
    "    print(f\"ğŸ“Š Classes: {model.output_shape[-1]}\")\n",
    "    print(f\"ğŸ“ Input shape: {model.input_shape}\")\n",
    "    print(\"ğŸ¯ Proceed to evaluation section\")\n",
    "    \n",
    "elif not DATASET_READY:\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"âš ï¸ SKIPPING TRAINING - NO DATASET AVAILABLE\")\n",
    "    print(\"=\"*50)\n",
    "    print(\"âŒ Cannot train without Stanford Cars dataset\")\n",
    "    print(\"ğŸ’¡ Please ensure dataset is downloaded and rerun\")\n",
    "    \n",
    "else:\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"ğŸš€ STARTING TRAINING WITH TENSORFLOW 2.19\")\n",
    "    print(\"=\"*50)\n",
    "\n",
    "    # Check if we need to fix the model for TF 2.19 compatibility\n",
    "    if not hasattr(model, '_tf219_fixed'):\n",
    "        print(\"ğŸ”§ Applying TensorFlow 2.19 compatibility fixes...\")\n",
    "        \n",
    "        # Get the current model's layers except the last one\n",
    "        layers_to_keep = model.layers[:-1]\n",
    "        \n",
    "        # Create a new final layer with explicit float32 dtype\n",
    "        final_layer = tf.keras.layers.Dense(\n",
    "            NUM_CLASSES,\n",
    "            activation='softmax',\n",
    "            kernel_regularizer=tf.keras.regularizers.l2(0.01),\n",
    "            dtype='float32',  # This is the key fix for mixed precision\n",
    "            name='predictions_fixed'\n",
    "        )\n",
    "        \n",
    "        # Rebuild the model\n",
    "        from tensorflow.keras.models import Sequential\n",
    "        model = Sequential(layers_to_keep + [final_layer])\n",
    "        \n",
    "        # Recompile with TF 2.19 compatible metrics\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.Adam(learning_rate=1e-4),\n",
    "            loss='categorical_crossentropy',\n",
    "            metrics=[\n",
    "                'accuracy',\n",
    "                tf.keras.metrics.TopKCategoricalAccuracy(k=5, name='top_5_accuracy', dtype='float32')\n",
    "            ]\n",
    "        )\n",
    "        \n",
    "        # Mark as fixed\n",
    "        model._tf219_fixed = True\n",
    "        print(\"âœ… Model fixed for TensorFlow 2.19 compatibility\")\n",
    "\n",
    "    # Create tf.data.Dataset from directory structure\n",
    "    print(\"ğŸ“ Setting up datasets...\")\n",
    "    \n",
    "    # Training dataset with augmentation\n",
    "    train_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "        TRAIN_DIR,\n",
    "        validation_split=0.2,\n",
    "        subset=\"training\",\n",
    "        seed=123,\n",
    "        image_size=(224, 224),\n",
    "        batch_size=BATCH_SIZE,\n",
    "        label_mode='categorical'\n",
    "    )\n",
    "\n",
    "    # Validation dataset\n",
    "    val_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "        TRAIN_DIR,\n",
    "        validation_split=0.2,\n",
    "        subset=\"validation\", \n",
    "        seed=123,\n",
    "        image_size=(224, 224),\n",
    "        batch_size=BATCH_SIZE,\n",
    "        label_mode='categorical'\n",
    "    )\n",
    "\n",
    "    # Test dataset\n",
    "    test_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "        TEST_DIR,\n",
    "        image_size=(224, 224),\n",
    "        batch_size=BATCH_SIZE,\n",
    "        label_mode='categorical',\n",
    "        shuffle=False\n",
    "    )\n",
    "\n",
    "    # Optimize datasets for performance\n",
    "    AUTOTUNE = tf.data.AUTOTUNE\n",
    "    train_ds = train_ds.cache().shuffle(1000).prefetch(buffer_size=AUTOTUNE)\n",
    "    val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "    test_ds = test_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "\n",
    "    print(f\"âœ… Datasets ready: train={len(train_ds)} batches, val={len(val_ds)} batches, test={len(test_ds)} batches\")\n",
    "    print(\"ğŸ¯ Using real Stanford Cars dataset\")\n",
    "\n",
    "    # Start training\n",
    "    print(\"\\nğŸ‹ï¸ STARTING TRAINING...\")\n",
    "    print(\"=\" * 30)\n",
    "    print(f\"ğŸ“Š Training on {NUM_CLASSES} car classes\")\n",
    "    print(f\"ğŸ¯ Max epochs: {EPOCHS} (early stopping enabled)\")\n",
    "\n",
    "    history = model.fit(\n",
    "        train_ds,\n",
    "        epochs=EPOCHS,\n",
    "        validation_data=val_ds,\n",
    "        callbacks=callbacks,\n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "    print(\"\\nâœ… TRAINING COMPLETED!\")\n",
    "    print(\"ğŸ“Š Training history saved to 'history' variable\")\n",
    "    print(\"ğŸ’¾ Best model saved as 'best_car_model_EfficientNetB4.keras'\")\n",
    "    \n",
    "    # Save training history to file for persistence\n",
    "    print(\"ğŸ’¾ Saving training history to file...\")\n",
    "    import pickle\n",
    "    import json\n",
    "    \n",
    "    try:\n",
    "        # Save as pickle file (preserves exact structure)\n",
    "        with open('training_history.pkl', 'wb') as f:\n",
    "            pickle.dump(history.history, f)\n",
    "        print(\"âœ… Training history saved as 'training_history.pkl'\")\n",
    "        \n",
    "        # Also save as JSON for readability (though less precise)\n",
    "        history_json = {}\n",
    "        for key, values in history.history.items():\n",
    "            history_json[key] = [float(v) for v in values]  # Convert to regular Python floats\n",
    "        \n",
    "        with open('training_history.json', 'w') as f:\n",
    "            json.dump(history_json, f, indent=2)\n",
    "        print(\"âœ… Training history also saved as 'training_history.json'\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âš ï¸  Could not save training history: {e}\")\n",
    "        print(\"ğŸ’¡ History is still available in 'history' variable for this session\")\n",
    "\n",
    "print(f\"\\nğŸ“‹ Final Status: {'Training Skipped (model exists)' if SKIP_TRAINING else 'Training Completed' if DATASET_READY else 'Training Skipped (no dataset)'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3c34513d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Training history already available in memory\n",
      "ğŸ“Š Available metrics: ['accuracy', 'loss', 'top_5_accuracy', 'val_accuracy', 'val_loss', 'val_top_5_accuracy', 'learning_rate']\n",
      "ğŸ“ˆ Training epochs: 20\n"
     ]
    }
   ],
   "source": [
    "# =======================================\n",
    "# LOAD TRAINING HISTORY (For Plotting)\n",
    "# =======================================\n",
    "\n",
    "def load_training_history():\n",
    "    \"\"\"\n",
    "    Load training history from saved files.\n",
    "    This ensures plotting works even after restarting the kernel.\n",
    "    \n",
    "    Returns:\n",
    "        dict: Training history or None if not found\n",
    "    \"\"\"\n",
    "    import pickle\n",
    "    import json\n",
    "    from pathlib import Path\n",
    "    \n",
    "    print(\"ğŸ”„ Loading training history...\")\n",
    "    \n",
    "    # Try to load from pickle file first (most accurate)\n",
    "    pickle_path = Path('training_history.pkl')\n",
    "    if pickle_path.exists():\n",
    "        try:\n",
    "            with open(pickle_path, 'rb') as f:\n",
    "                history_data = pickle.load(f)\n",
    "            print(\"âœ… Loaded training history from 'training_history.pkl'\")\n",
    "            return history_data\n",
    "        except Exception as e:\n",
    "            print(f\"âš ï¸  Could not load pickle file: {e}\")\n",
    "    \n",
    "    # Fallback to JSON file\n",
    "    json_path = Path('training_history.json')\n",
    "    if json_path.exists():\n",
    "        try:\n",
    "            with open(json_path, 'r') as f:\n",
    "                history_data = json.load(f)\n",
    "            print(\"âœ… Loaded training history from 'training_history.json'\")\n",
    "            return history_data\n",
    "        except Exception as e:\n",
    "            print(f\"âš ï¸  Could not load JSON file: {e}\")\n",
    "    \n",
    "    print(\"âŒ No training history files found\")\n",
    "    print(\"ğŸ’¡ If you've trained the model, the history should be in the 'history' variable\")\n",
    "    return None\n",
    "\n",
    "# Load history if not already available\n",
    "if 'history' not in globals() or history is None:\n",
    "    print(\"ğŸ“Š TRAINING HISTORY NOT FOUND IN MEMORY\")\n",
    "    print(\"ğŸ” Attempting to load from saved files...\")\n",
    "    \n",
    "    loaded_history = load_training_history()\n",
    "    \n",
    "    if loaded_history:\n",
    "        # Create a mock history object with the loaded data\n",
    "        class MockHistory:\n",
    "            def __init__(self, history_dict):\n",
    "                self.history = history_dict\n",
    "        \n",
    "        history = MockHistory(loaded_history)\n",
    "        print(\"âœ… Training history restored successfully!\")\n",
    "        print(f\"ğŸ“Š Available metrics: {list(history.history.keys())}\")\n",
    "        print(f\"ğŸ“ˆ Training epochs: {len(history.history.get('loss', []))}\")\n",
    "    else:\n",
    "        print(\"âŒ Could not load training history\")\n",
    "        print(\"ğŸ’¡ You may need to train the model first\")\n",
    "        history = None\n",
    "        \n",
    "else:\n",
    "    print(\"âœ… Training history already available in memory\")\n",
    "    if hasattr(history, 'history'):\n",
    "        print(f\"ğŸ“Š Available metrics: {list(history.history.keys())}\")\n",
    "        print(f\"ğŸ“ˆ Training epochs: {len(history.history.get('loss', []))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2ba71c1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“ AVAILABLE TRAINING HISTORY FILES\n",
      "========================================\n",
      "âœ… training_history.pkl (1.4KB, modified: 2025-07-24 02:33:01)\n",
      "âœ… training_history.json (3.5KB, modified: 2025-07-24 02:33:01)\n",
      "\n",
      "ğŸ’¡ Use load_training_history() to load the main history file\n",
      "ğŸ’¾ Use save_current_history() to save current history\n"
     ]
    }
   ],
   "source": [
    "# =======================================\n",
    "# TRAINING HISTORY MANAGEMENT UTILITIES\n",
    "# =======================================\n",
    "from datetime import datetime\n",
    "def save_current_history():\n",
    "    \"\"\"\n",
    "    Manually save the current training history to files.\n",
    "    Useful if you want to preserve history from fine-tuning or additional training.\n",
    "    \"\"\"\n",
    "    if 'history' not in globals() or history is None:\n",
    "        print(\"âŒ No training history available to save\")\n",
    "        return False\n",
    "        \n",
    "    import pickle\n",
    "    import json\n",
    "    \n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    \n",
    "    try:\n",
    "        # Save as pickle file (most accurate)\n",
    "        pickle_file = f'training_history_{timestamp}.pkl'\n",
    "        with open(pickle_file, 'wb') as f:\n",
    "            pickle.dump(history.history, f)\n",
    "        \n",
    "        # Also save as main file\n",
    "        with open('training_history.pkl', 'wb') as f:\n",
    "            pickle.dump(history.history, f)\n",
    "        \n",
    "        print(f\"âœ… Training history saved as '{pickle_file}'\")\n",
    "        print(\"âœ… Training history updated in 'training_history.pkl'\")\n",
    "        \n",
    "        # Save as JSON for readability\n",
    "        history_json = {}\n",
    "        for key, values in history.history.items():\n",
    "            history_json[key] = [float(v) for v in values]\n",
    "        \n",
    "        json_file = f'training_history_{timestamp}.json'\n",
    "        with open(json_file, 'w') as f:\n",
    "            json.dump(history_json, f, indent=2)\n",
    "            \n",
    "        with open('training_history.json', 'w') as f:\n",
    "            json.dump(history_json, f, indent=2)\n",
    "            \n",
    "        print(f\"âœ… Training history also saved as '{json_file}'\")\n",
    "        \n",
    "        return True\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Error saving training history: {e}\")\n",
    "        return False\n",
    "\n",
    "def check_history_files():\n",
    "    \"\"\"Check what training history files are available\"\"\"\n",
    "    from pathlib import Path\n",
    "    import os\n",
    "    \n",
    "    print(\"ğŸ“ AVAILABLE TRAINING HISTORY FILES\")\n",
    "    print(\"=\" * 40)\n",
    "    \n",
    "    # Check for main files\n",
    "    main_files = ['training_history.pkl', 'training_history.json']\n",
    "    for filename in main_files:\n",
    "        path = Path(filename)\n",
    "        if path.exists():\n",
    "            size = path.stat().st_size / 1024  # KB\n",
    "            mod_time = path.stat().st_mtime\n",
    "            mod_time_str = datetime.fromtimestamp(mod_time).strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "            print(f\"âœ… {filename} ({size:.1f}KB, modified: {mod_time_str})\")\n",
    "        else:\n",
    "            print(f\"âŒ {filename} - Not found\")\n",
    "    \n",
    "    # Check for timestamped files\n",
    "    pkl_files = list(Path('.').glob('training_history_*.pkl'))\n",
    "    json_files = list(Path('.').glob('training_history_*.json'))\n",
    "    \n",
    "    if pkl_files or json_files:\n",
    "        print(f\"\\nğŸ“… TIMESTAMPED HISTORY FILES:\")\n",
    "        all_files = pkl_files + json_files\n",
    "        for file_path in sorted(all_files):\n",
    "            size = file_path.stat().st_size / 1024  # KB\n",
    "            mod_time = file_path.stat().st_mtime\n",
    "            mod_time_str = datetime.fromtimestamp(mod_time).strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "            print(f\"   ğŸ“„ {file_path.name} ({size:.1f}KB, {mod_time_str})\")\n",
    "    \n",
    "    print(f\"\\nğŸ’¡ Use load_training_history() to load the main history file\")\n",
    "    print(f\"ğŸ’¾ Use save_current_history() to save current history\")\n",
    "\n",
    "# Check what history files are currently available\n",
    "check_history_files()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2138c56",
   "metadata": {},
   "source": [
    "# 5. Model Evaluation\n",
    "\n",
    "## Objective\n",
    "Evaluate the trained model on test data and compute comprehensive metrics.\n",
    "\n",
    "**Thought Process: With 196 classes, top-5 accuracy is important to assess if the model is close to correct. We'll evaluate on test set for final metrics, plot training history for trends, and analyze confusion matrix for common errors, expecting some confusion between similar car models.**\n",
    "\n",
    "## Evaluation Metrics\n",
    "- **Top-1 Accuracy**: Standard classification accuracy\n",
    "- **Top-5 Accuracy**: Accuracy if correct class is in top 5 predictions\n",
    "- **Confusion Matrix**: Detailed class-wise performance\n",
    "- **Classification Report**: Precision, Recall, F1-Score per class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "10cd2a1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¨ TRAINING HISTORY PLOTTING READY!\n",
      "===================================\n",
      "ğŸ’¡ To plot training history anytime, use:\n",
      "   plot_training_history()  # Uses loaded history\n",
      "   plot_training_history(history)  # Uses specific history object\n",
      "\n",
      "ğŸ”„ Attempting to plot current history...\n",
      "ğŸ“ˆ PLOTTING TRAINING HISTORY\n",
      "==============================\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x500 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ’¾ Plots saved as 'training_plots_20250724_023301.png' and 'training_plots.png'\n",
      "\n",
      "ğŸ“Š TRAINING SUMMARY:\n",
      "   Total epochs: 20\n",
      "   Available metrics: accuracy, loss, top_5_accuracy, val_accuracy, val_loss, val_top_5_accuracy, learning_rate\n",
      "âœ… Training history plotted successfully!\n"
     ]
    }
   ],
   "source": [
    "# =======================================\n",
    "# PLOT TRAINING HISTORY (ANYTIME)\n",
    "# =======================================\n",
    "\n",
    "def plot_training_history(history_obj=None, save_plots=True):\n",
    "    \"\"\"\n",
    "    Plot training history with automatic loading if not provided.\n",
    "    This function works even after kernel restarts.\n",
    "    \n",
    "    Args:\n",
    "        history_obj: History object (if None, will try to load from files)\n",
    "        save_plots: Whether to save plots as image files\n",
    "    \"\"\"\n",
    "    import matplotlib.pyplot as plt\n",
    "    \n",
    "    # Use provided history or try to load it\n",
    "    if history_obj is None:\n",
    "        if 'history' in globals() and history is not None:\n",
    "            history_obj = history\n",
    "        else:\n",
    "            print(\"ğŸ”„ No history provided, attempting to load from files...\")\n",
    "            loaded_history = load_training_history()\n",
    "            if loaded_history:\n",
    "                class MockHistory:\n",
    "                    def __init__(self, history_dict):\n",
    "                        self.history = history_dict\n",
    "                history_obj = MockHistory(loaded_history)\n",
    "            else:\n",
    "                print(\"âŒ No training history available for plotting\")\n",
    "                return False\n",
    "    \n",
    "    if not hasattr(history_obj, 'history') or not history_obj.history:\n",
    "        print(\"âŒ Invalid history object\")\n",
    "        return False\n",
    "    \n",
    "    print(\"ğŸ“ˆ PLOTTING TRAINING HISTORY\")\n",
    "    print(\"=\" * 30)\n",
    "    \n",
    "    # Clear any existing plots\n",
    "    plt.clf()\n",
    "    plt.close('all')\n",
    "    \n",
    "    # Determine number of subplots based on available metrics\n",
    "    metrics = list(history_obj.history.keys())\n",
    "    has_top5 = any('top_5_accuracy' in key for key in metrics)\n",
    "    n_plots = 3 if has_top5 else 2\n",
    "    \n",
    "    fig, axes = plt.subplots(1, n_plots, figsize=(5*n_plots, 5))\n",
    "    if n_plots == 1:\n",
    "        axes = [axes]\n",
    "    elif n_plots == 2:\n",
    "        axes = list(axes)\n",
    "    \n",
    "    try:\n",
    "        # Accuracy plot\n",
    "        if 'accuracy' in history_obj.history:\n",
    "            axes[0].plot(history_obj.history['accuracy'], label='Training', linewidth=2, color='blue')\n",
    "            if 'val_accuracy' in history_obj.history:\n",
    "                axes[0].plot(history_obj.history['val_accuracy'], label='Validation', linewidth=2, color='orange')\n",
    "            axes[0].set_title('Model Accuracy Over Time', fontsize=14, fontweight='bold')\n",
    "            axes[0].set_xlabel('Epoch')\n",
    "            axes[0].set_ylabel('Accuracy')\n",
    "            axes[0].legend()\n",
    "            axes[0].grid(True, alpha=0.3)\n",
    "            axes[0].set_ylim([0, 1])\n",
    "            \n",
    "            # Add final accuracy text\n",
    "            final_train_acc = history_obj.history['accuracy'][-1]\n",
    "            final_val_acc = history_obj.history.get('val_accuracy', [0])[-1] if 'val_accuracy' in history_obj.history else 0\n",
    "            axes[0].text(0.02, 0.98, f'Final: Train={final_train_acc:.3f}, Val={final_val_acc:.3f}', \n",
    "                        transform=axes[0].transAxes, verticalalignment='top', \n",
    "                        bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))\n",
    "        \n",
    "        # Loss plot\n",
    "        if 'loss' in history_obj.history:\n",
    "            axes[1].plot(history_obj.history['loss'], label='Training', linewidth=2, color='red')\n",
    "            if 'val_loss' in history_obj.history:\n",
    "                axes[1].plot(history_obj.history['val_loss'], label='Validation', linewidth=2, color='purple')\n",
    "            axes[1].set_title('Model Loss Over Time', fontsize=14, fontweight='bold')\n",
    "            axes[1].set_xlabel('Epoch')\n",
    "            axes[1].set_ylabel('Loss')\n",
    "            axes[1].legend()\n",
    "            axes[1].grid(True, alpha=0.3)\n",
    "            \n",
    "            # Add final loss text\n",
    "            final_train_loss = history_obj.history['loss'][-1]\n",
    "            final_val_loss = history_obj.history.get('val_loss', [0])[-1] if 'val_loss' in history_obj.history else 0\n",
    "            axes[1].text(0.02, 0.98, f'Final: Train={final_train_loss:.3f}, Val={final_val_loss:.3f}', \n",
    "                        transform=axes[1].transAxes, verticalalignment='top',\n",
    "                        bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))\n",
    "        \n",
    "        # Top-5 accuracy plot if available\n",
    "        if has_top5 and n_plots >= 3:\n",
    "            if 'top_5_accuracy' in history_obj.history:\n",
    "                axes[2].plot(history_obj.history['top_5_accuracy'], label='Training', linewidth=2, color='green')\n",
    "                if 'val_top_5_accuracy' in history_obj.history:\n",
    "                    axes[2].plot(history_obj.history['val_top_5_accuracy'], label='Validation', linewidth=2, color='brown')\n",
    "                axes[2].set_title('Top-5 Accuracy Over Time', fontsize=14, fontweight='bold')\n",
    "                axes[2].set_xlabel('Epoch')\n",
    "                axes[2].set_ylabel('Top-5 Accuracy')\n",
    "                axes[2].legend()\n",
    "                axes[2].grid(True, alpha=0.3)\n",
    "                axes[2].set_ylim([0, 1])\n",
    "                \n",
    "                # Add final top-5 accuracy text\n",
    "                final_train_top5 = history_obj.history['top_5_accuracy'][-1]\n",
    "                final_val_top5 = history_obj.history.get('val_top_5_accuracy', [0])[-1] if 'val_top_5_accuracy' in history_obj.history else 0\n",
    "                axes[2].text(0.02, 0.98, f'Final: Train={final_train_top5:.3f}, Val={final_val_top5:.3f}', \n",
    "                            transform=axes[2].transAxes, verticalalignment='top',\n",
    "                            bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        # Save plots if requested\n",
    "        if save_plots:\n",
    "            try:\n",
    "                from datetime import datetime\n",
    "                timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "                plot_filename = f'training_plots_{timestamp}.png'\n",
    "                fig.savefig(plot_filename, dpi=300, bbox_inches='tight')\n",
    "                \n",
    "                # Also save as main plot file\n",
    "                fig.savefig('training_plots.png', dpi=300, bbox_inches='tight')\n",
    "                print(f\"ğŸ’¾ Plots saved as '{plot_filename}' and 'training_plots.png'\")\n",
    "            except Exception as e:\n",
    "                print(f\"âš ï¸  Could not save plots: {e}\")\n",
    "        \n",
    "        # Display summary\n",
    "        epochs = len(history_obj.history.get('loss', []))\n",
    "        print(f\"\\nğŸ“Š TRAINING SUMMARY:\")\n",
    "        print(f\"   Total epochs: {epochs}\")\n",
    "        print(f\"   Available metrics: {', '.join(metrics)}\")\n",
    "        \n",
    "        plt.close(fig)\n",
    "        return True\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Error creating plots: {e}\")\n",
    "        plt.close(fig)\n",
    "        return False\n",
    "\n",
    "# Demonstrate plotting functionality\n",
    "print(\"ğŸ¨ TRAINING HISTORY PLOTTING READY!\")\n",
    "print(\"=\" * 35)\n",
    "print(\"ğŸ’¡ To plot training history anytime, use:\")\n",
    "print(\"   plot_training_history()  # Uses loaded history\")\n",
    "print(\"   plot_training_history(history)  # Uses specific history object\")\n",
    "print(\"\\nğŸ”„ Attempting to plot current history...\")\n",
    "\n",
    "if plot_training_history():\n",
    "    print(\"âœ… Training history plotted successfully!\")\n",
    "else:\n",
    "    print(\"â„¹ï¸  No training history available to plot yet\")\n",
    "    print(\"ğŸ‹ï¸  Train the model first, then this will work automatically\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "548b90f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“Š EVALUATING MODEL PERFORMANCE\n",
      "===================================\n",
      "ğŸ¯ Validation Set Results:\n",
      "   Loss: 3.1674\n",
      "   Accuracy: 0.4791 (47.91%)\n",
      "   Top-5 Accuracy: 0.7475 (74.75%)\n",
      "\n",
      "ğŸ¯ Test Set Results:\n",
      "   Loss: 3.1674\n",
      "   Accuracy: 0.4791 (47.91%)\n",
      "   Top-5 Accuracy: 0.7475 (74.75%)\n",
      "\n",
      "ğŸ¯ Test Set Results:\n",
      "   Loss: 3.1495\n",
      "   Accuracy: 0.4873 (48.73%)\n",
      "   Top-5 Accuracy: 0.7623 (76.23%)\n",
      "\n",
      "âœ… Model evaluation completed!\n",
      "   Loss: 3.1495\n",
      "   Accuracy: 0.4873 (48.73%)\n",
      "   Top-5 Accuracy: 0.7623 (76.23%)\n",
      "\n",
      "âœ… Model evaluation completed!\n"
     ]
    }
   ],
   "source": [
    "# =======================================\n",
    "# MODEL EVALUATION AND RESULTS\n",
    "# =======================================\n",
    "from matplotlib import pyplot as plt    \n",
    "\n",
    "print(\"ğŸ“Š EVALUATING MODEL PERFORMANCE\")\n",
    "print(\"=\" * 35)\n",
    "\n",
    "if not DATASET_READY:\n",
    "    print(\"âš ï¸ Dataset not available - skipping evaluation\")\n",
    "    print(\"ğŸ’¡ Model is ready for inference with external data\")\n",
    "    print(f\"ğŸ“‹ Model summary:\")\n",
    "    print(f\"   Architecture: {model.name}\")\n",
    "    print(f\"   Parameters: {model.count_params():,}\")\n",
    "    print(f\"   Input shape: {model.input_shape}\")\n",
    "    print(f\"   Output classes: {model.output_shape[-1]}\")\n",
    "    \n",
    "else:\n",
    "    # Ensure we have the datasets available\n",
    "    if 'val_ds' not in globals() or 'test_ds' not in globals():\n",
    "        print(\"ğŸ”„ Creating evaluation datasets...\")\n",
    "        \n",
    "        # Create datasets for evaluation\n",
    "        val_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "            TRAIN_DIR,\n",
    "            validation_split=0.2,\n",
    "            subset=\"validation\", \n",
    "            seed=123,\n",
    "            image_size=(224, 224),\n",
    "            batch_size=BATCH_SIZE,\n",
    "            label_mode='categorical'\n",
    "        )\n",
    "\n",
    "        test_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "            TEST_DIR,\n",
    "            image_size=(224, 224),\n",
    "            batch_size=BATCH_SIZE,\n",
    "            label_mode='categorical',\n",
    "            shuffle=False\n",
    "        )\n",
    "        \n",
    "        # Optimize for evaluation\n",
    "        val_ds = val_ds.cache().prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "        test_ds = test_ds.cache().prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "        \n",
    "        print(\"âœ… Evaluation datasets ready\")\n",
    "\n",
    "    # Evaluate on validation set\n",
    "    print(\"ğŸ¯ Validation Set Results:\")\n",
    "    val_results = model.evaluate(val_ds, verbose=0, return_dict=True)\n",
    "    print(f\"   Loss: {val_results['loss']:.4f}\")\n",
    "    print(f\"   Accuracy: {val_results['accuracy']:.4f} ({val_results['accuracy']*100:.2f}%)\")\n",
    "    if 'top_5_accuracy' in val_results:\n",
    "        print(f\"   Top-5 Accuracy: {val_results['top_5_accuracy']:.4f} ({val_results['top_5_accuracy']*100:.2f}%)\")\n",
    "\n",
    "    # Evaluate on test set\n",
    "    print(\"\\nğŸ¯ Test Set Results:\")\n",
    "    test_results = model.evaluate(test_ds, verbose=0, return_dict=True)\n",
    "    print(f\"   Loss: {test_results['loss']:.4f}\")\n",
    "    print(f\"   Accuracy: {test_results['accuracy']:.4f} ({test_results['accuracy']*100:.2f}%)\")\n",
    "    if 'top_5_accuracy' in test_results:\n",
    "        print(f\"   Top-5 Accuracy: {test_results['top_5_accuracy']:.4f} ({test_results['top_5_accuracy']*100:.2f}%)\")\n",
    "\n",
    "print(\"\\nâœ… Model evaluation completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9ede928",
   "metadata": {},
   "source": [
    "# 6. Model Export and Deployment Preparation\n",
    "\n",
    "## Objective\n",
    "Save the trained model in multiple formats and generate necessary deployment files for the API service.\n",
    "\n",
    "**Thought Process: We'll save in multiple formats for flexibility: H5 for legacy, .keras for native TensorFlow, and SavedModel for production. FastAPI is chosen for its modern features, and Docker ensures scalable deployment. Class mapping ensures predictions map to car names, crucial for user-facing API.**\n",
    "\n",
    "## Export Process\n",
    "- **H5 Format**: Compatible with existing FastAPI service\n",
    "- **SavedModel Format**: TensorFlow's recommended production format  \n",
    "- **Class Mapping**: JSON file mapping class indices to car type names\n",
    "- **API Compatibility**: Verification that saved model works with the API\n",
    "\n",
    "## Generated Files\n",
    "- `car_classification_model.h5` - H5 model (legacy format, for backward compatibility)\n",
    "- `best_car_model.keras` - Keras model (recommended native format)\n",
    "- `models/car_classification_savedmodel/` - SavedModel format for TF Serving/TF Lite\n",
    "- `class_mapping.json` - Class index to name mapping\n",
    "- `prediction_example.py` - Example usage code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a494ef54",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸš€ STARTING MODEL EXPORT PIPELINE\n",
      "==================================================\n",
      "ğŸ’¾ Saving Model and Generating Deployment Files...\n",
      "==================================================\n",
      "âœ… Model saved as H5: car_classification_model.h5 (172.6 MB)\n",
      "   âš ï¸ H5 format is legacy - consider using .keras format for new projects\n",
      "âœ… Model saved as H5: car_classification_model.h5 (172.6 MB)\n",
      "   âš ï¸ H5 format is legacy - consider using .keras format for new projects\n",
      "âœ… Model saved as Keras: best_car_model.keras (250.5 MB)\n",
      "âœ… Model saved as Keras: best_car_model.keras (250.5 MB)\n",
      "Saved artifact at 'models/car_classification_savedmodel'. The following endpoints are available:\n",
      "\n",
      "* Endpoint 'serve'\n",
      "  args_0 (POSITIONAL_ONLY): TensorSpec(shape=(None, 224, 224, 3), dtype=tf.float16, name='keras_tensor_186')\n",
      "Output Type:\n",
      "  TensorSpec(shape=(None, 196), dtype=tf.float32, name=None)\n",
      "Captures:\n",
      "  129245575618512: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129245575611792: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129245575617360: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129245575618896: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129245575615248: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129245575618704: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129245575620816: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129245575622160: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129245575623504: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129245575623696: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129245575621968: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129245575621584: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129245575624080: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129245575623888: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129245575622544: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129245575625040: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129245575624848: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129245575624272: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129245575624656: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129245575621008: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129245575616784: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129245575617168: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129245575621200: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129245575621392: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129245575620624: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129245575617552: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129245575626384: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129245575624464: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129245575625424: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129245575625232: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129245575626576: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129245575623312: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129245575622928: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129245575622352: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129245575626000: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129245575626192: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129245499703952: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129245499703760: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129245499703568: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129245499705488: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129245499705296: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129245499703376: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129245499705104: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129245499704528: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129245499704336: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129245499706640: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129245499706448: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129245499704720: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129245499707024: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129245499706832: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129245499705872: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129245499707984: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129245499707792: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129245499707216: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129245499708368: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129245499708176: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129245499704912: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129245499709328: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129245499709136: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129245499708560: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129245499708944: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129245499705680: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129245499704144: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129245499710480: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129245499710288: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129245499706256: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129245499711248: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129245499710672: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129245499708752: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129245499712784: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129245499712592: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129245499710864: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129245499712400: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129245499711824: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129245499709904: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129245499713936: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129245499713744: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129245499712016: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129245499713552: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129245499712976: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129245499710096: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129245499709520: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129245499707600: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129245499711632: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129245499711440: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129245499709712: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129245499711056: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129245499715088: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129245499714896: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129245499713168: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129245499714704: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129245499714128: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129245499712208: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129245499716240: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129245499716048: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129245499714320: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129245499715856: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129245499715280: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129245499713360: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129245499717392: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129245499717200: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129245499715472: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129245499717008: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129245499716432: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129245499714512: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129245499718544: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129245499718352: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129245499716624: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129245499718160: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129245499717584: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129245499718928: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129245499719120: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129245499719504: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129245499717776: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129245499717968: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129245499715664: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129245499716816: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129243773650128: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129245499718736: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129245499719312: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129243773649744: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129243773649360: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129243773648976: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129243773651280: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129243773651088: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129243773649168: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129243773650896: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129243773650320: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129243773649552: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129243773652432: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129243773652240: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129243773650512: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129243773652048: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129243773651472: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129243773649936: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129243773653584: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129243773653392: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129243773651664: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129243773653200: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129243773652624: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129243773650704: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129243773654736: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129243773654544: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129243773652816: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129243773655504: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129243773654928: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129243773653008: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129243773657040: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129243773656848: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129243773655120: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129243773656656: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129243773656080: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129243773654160: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129243773658192: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129243773658000: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129243773656272: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129243773657808: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129243773657232: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129243773654352: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129243773653776: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129243773651856: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129243773655888: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129243773655696: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129243773653968: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129243773655312: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129243773659344: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129243773659152: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129243773657424: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129243773658960: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129243773658384: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129243773656464: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129243773660496: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129243773660304: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129243773658576: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129243773660112: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129243773659536: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129243773657616: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129243773661648: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129243773661456: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129243773659728: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129243773661264: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129243773660688: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129243773658768: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129243773662800: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129243773662608: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129243773660880: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129243773662416: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129243773661840: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129243773659920: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129243773663952: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129243773663760: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129243773662032: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129243773663568: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129243773662992: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129243773661072: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129243773664720: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129243773664912: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129243773663184: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129243773665104: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129243773662224: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129243773664144: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129243773664528: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129243773663376: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129243773664336: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129244377465104: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129244377465680: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129244377466064: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129244377467024: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129244377466832: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129244377466256: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129244377466640: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129244377465872: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129244377465488: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129244377468176: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129244377467984: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129244377465296: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129244377467792: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129244377467216: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129244377464912: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129244377469328: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129244377469136: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129244377467408: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129244377468944: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129244377468368: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129244377466448: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129244377470480: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129244377470288: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129244377468560: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129244377470096: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129244377469520: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129244377467600: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129244377471632: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129244377471440: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129244377469712: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129244377471248: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129244377470672: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129244377468752: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129244377472784: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129244377472592: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129244377470864: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129244377472400: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129244377471824: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129244377469904: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129244377473936: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129244377473744: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129244377472016: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129244377473552: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129244377472976: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129244377471056: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129244377475088: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129244377474896: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129244377473168: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129244377474704: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129244377474128: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129244377472208: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129244377476240: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129244377476048: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129244377474320: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129244377477008: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129244377476432: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129244377474512: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129244377478544: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129244377478352: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129244377476624: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129244377478160: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129244377477584: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129244377475664: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129244377479696: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129244377479504: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129244377477776: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129244377479312: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129244377478736: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129244377475856: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129244377475280: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129244377473360: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129244377477392: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129244377477200: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129244377475472: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129244377476816: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129244377480848: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129244377480656: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129244377478928: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129244377480464: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129244377480080: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129244377477968: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129244377481040: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129244377479120: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129244377480272: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129244377479888: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129245329310736: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129245329311504: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129245329311696: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129245329310160: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129245329311312: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129245329310928: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129245329310352: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129245329309776: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129245329312848: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129245329312656: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129245329309968: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129245329312464: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129245329311888: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129245329310544: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129245329314000: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129245329313808: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129245329312080: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129245329313616: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129245329313040: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129245329311120: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129245329315152: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129245329314960: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129245329313232: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129245329314768: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129245329314192: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129245329312272: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129245329316304: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129245329316112: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129245329314384: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129245329315536: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129245329317264: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129245329317648: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129245329318608: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129245329318416: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129245329317840: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129245329318224: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129245329317456: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129245329320336: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129245329322064: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "Saved artifact at 'models/car_classification_savedmodel'. The following endpoints are available:\n",
      "\n",
      "* Endpoint 'serve'\n",
      "  args_0 (POSITIONAL_ONLY): TensorSpec(shape=(None, 224, 224, 3), dtype=tf.float16, name='keras_tensor_186')\n",
      "Output Type:\n",
      "  TensorSpec(shape=(None, 196), dtype=tf.float32, name=None)\n",
      "Captures:\n",
      "  129245575618512: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129245575611792: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129245575617360: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129245575618896: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129245575615248: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129245575618704: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129245575620816: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129245575622160: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129245575623504: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129245575623696: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129245575621968: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129245575621584: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129245575624080: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129245575623888: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129245575622544: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129245575625040: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129245575624848: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129245575624272: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129245575624656: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129245575621008: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129245575616784: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129245575617168: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129245575621200: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129245575621392: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129245575620624: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129245575617552: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129245575626384: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129245575624464: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129245575625424: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129245575625232: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129245575626576: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129245575623312: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129245575622928: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129245575622352: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129245575626000: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129245575626192: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129245499703952: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129245499703760: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129245499703568: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129245499705488: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129245499705296: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129245499703376: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129245499705104: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129245499704528: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129245499704336: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129245499706640: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129245499706448: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129245499704720: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129245499707024: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129245499706832: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129245499705872: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129245499707984: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129245499707792: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129245499707216: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129245499708368: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129245499708176: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129245499704912: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129245499709328: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129245499709136: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129245499708560: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129245499708944: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129245499705680: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129245499704144: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129245499710480: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129245499710288: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129245499706256: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129245499711248: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129245499710672: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129245499708752: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129245499712784: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129245499712592: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129245499710864: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129245499712400: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129245499711824: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129245499709904: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129245499713936: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129245499713744: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129245499712016: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129245499713552: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129245499712976: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129245499710096: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129245499709520: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129245499707600: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129245499711632: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129245499711440: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129245499709712: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129245499711056: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129245499715088: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129245499714896: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129245499713168: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129245499714704: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129245499714128: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129245499712208: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129245499716240: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129245499716048: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129245499714320: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129245499715856: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129245499715280: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129245499713360: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129245499717392: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129245499717200: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129245499715472: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129245499717008: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129245499716432: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129245499714512: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129245499718544: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129245499718352: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129245499716624: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129245499718160: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129245499717584: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129245499718928: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129245499719120: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129245499719504: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129245499717776: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129245499717968: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129245499715664: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129245499716816: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129243773650128: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129245499718736: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129245499719312: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129243773649744: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129243773649360: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129243773648976: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129243773651280: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129243773651088: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129243773649168: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129243773650896: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129243773650320: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129243773649552: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129243773652432: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129243773652240: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129243773650512: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129243773652048: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129243773651472: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129243773649936: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129243773653584: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129243773653392: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129243773651664: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129243773653200: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129243773652624: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129243773650704: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129243773654736: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129243773654544: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129243773652816: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129243773655504: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129243773654928: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129243773653008: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129243773657040: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129243773656848: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129243773655120: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129243773656656: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129243773656080: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129243773654160: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129243773658192: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129243773658000: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129243773656272: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129243773657808: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129243773657232: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129243773654352: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129243773653776: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129243773651856: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129243773655888: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129243773655696: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129243773653968: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129243773655312: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129243773659344: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129243773659152: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129243773657424: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129243773658960: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129243773658384: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129243773656464: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129243773660496: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129243773660304: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129243773658576: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129243773660112: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129243773659536: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129243773657616: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129243773661648: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129243773661456: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129243773659728: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129243773661264: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129243773660688: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129243773658768: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129243773662800: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129243773662608: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129243773660880: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129243773662416: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129243773661840: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129243773659920: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129243773663952: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129243773663760: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129243773662032: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129243773663568: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129243773662992: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129243773661072: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129243773664720: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129243773664912: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129243773663184: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129243773665104: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129243773662224: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129243773664144: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129243773664528: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129243773663376: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129243773664336: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129244377465104: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129244377465680: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129244377466064: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129244377467024: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129244377466832: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129244377466256: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129244377466640: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129244377465872: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129244377465488: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129244377468176: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129244377467984: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129244377465296: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129244377467792: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129244377467216: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129244377464912: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129244377469328: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129244377469136: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129244377467408: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129244377468944: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129244377468368: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129244377466448: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129244377470480: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129244377470288: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129244377468560: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129244377470096: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129244377469520: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129244377467600: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129244377471632: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129244377471440: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129244377469712: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129244377471248: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129244377470672: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129244377468752: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129244377472784: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129244377472592: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129244377470864: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129244377472400: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129244377471824: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129244377469904: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129244377473936: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129244377473744: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129244377472016: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129244377473552: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129244377472976: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129244377471056: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129244377475088: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129244377474896: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129244377473168: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129244377474704: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129244377474128: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129244377472208: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129244377476240: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129244377476048: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129244377474320: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129244377477008: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129244377476432: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129244377474512: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129244377478544: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129244377478352: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129244377476624: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129244377478160: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129244377477584: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129244377475664: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129244377479696: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129244377479504: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129244377477776: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129244377479312: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129244377478736: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129244377475856: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129244377475280: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129244377473360: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129244377477392: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129244377477200: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129244377475472: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129244377476816: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129244377480848: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129244377480656: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129244377478928: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129244377480464: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129244377480080: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129244377477968: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129244377481040: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129244377479120: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129244377480272: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129244377479888: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129245329310736: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129245329311504: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129245329311696: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129245329310160: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129245329311312: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129245329310928: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129245329310352: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129245329309776: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129245329312848: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129245329312656: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129245329309968: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129245329312464: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129245329311888: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129245329310544: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129245329314000: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129245329313808: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129245329312080: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129245329313616: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129245329313040: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129245329311120: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129245329315152: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129245329314960: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129245329313232: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129245329314768: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129245329314192: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129245329312272: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129245329316304: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129245329316112: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129245329314384: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129245329315536: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129245329317264: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129245329317648: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129245329318608: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129245329318416: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129245329317840: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129245329318224: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129245329317456: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129245329320336: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  129245329322064: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "âœ… Model exported as SavedModel: models/car_classification_savedmodel\n",
      "âœ… Extracted 196 class names from directory structure\n",
      "âœ… Class mapping saved: class_mapping.json\n",
      "ğŸ“Š Total classes: 196\n",
      "\n",
      "ğŸ·ï¸ Sample class mappings:\n",
      "   0: AM General Hummer SUV 2000\n",
      "   1: Acura Integra Type R 2001\n",
      "   2: Acura RL Sedan 2012\n",
      "   3: Acura TL Sedan 2012\n",
      "   4: Acura TL Type-S 2008\n",
      "   5: Acura TSX Sedan 2012\n",
      "   6: Acura ZDX Hatchback 2012\n",
      "   7: Aston Martin V8 Vantage Convertible 2012\n",
      "   8: Aston Martin V8 Vantage Coupe 2012\n",
      "   9: Aston Martin Virage Convertible 2012\n",
      "   ... and 186 more classes\n",
      "\n",
      "ğŸ”§ Verifying API Compatibility...\n",
      "âœ… Model exported as SavedModel: models/car_classification_savedmodel\n",
      "âœ… Extracted 196 class names from directory structure\n",
      "âœ… Class mapping saved: class_mapping.json\n",
      "ğŸ“Š Total classes: 196\n",
      "\n",
      "ğŸ·ï¸ Sample class mappings:\n",
      "   0: AM General Hummer SUV 2000\n",
      "   1: Acura Integra Type R 2001\n",
      "   2: Acura RL Sedan 2012\n",
      "   3: Acura TL Sedan 2012\n",
      "   4: Acura TL Type-S 2008\n",
      "   5: Acura TSX Sedan 2012\n",
      "   6: Acura ZDX Hatchback 2012\n",
      "   7: Aston Martin V8 Vantage Convertible 2012\n",
      "   8: Aston Martin V8 Vantage Coupe 2012\n",
      "   9: Aston Martin Virage Convertible 2012\n",
      "   ... and 186 more classes\n",
      "\n",
      "ğŸ”§ Verifying API Compatibility...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Model loads successfully\n",
      "âœ… Prediction shape: (1, 196)\n",
      "âœ… Expected shape: (1, 196)\n",
      "âœ… Class mapping loads successfully\n",
      "âœ… Number of classes: 196\n",
      "âœ… Model output matches class mapping!\n",
      "âœ… Sample prediction: Class 106 -> Ford Edge SUV 2012\n",
      "ğŸ¯ Model is ready for deployment!\n",
      "\n",
      "ğŸ‰ Model Export Complete!\n",
      "==================================================\n",
      "ğŸ“ Generated Files:\n",
      "   âœ… car_classification_model.h5 - H5 model (legacy format)\n",
      "   âœ… best_car_model.keras - Keras model (recommended)\n",
      "   âœ… models/car_classification_savedmodel - SavedModel for production\n",
      "   âœ… class_mapping.json - Class mapping\n",
      "   âœ… prediction_example.py - Usage example\n",
      "\n",
      "ğŸš€ Your model is ready for deployment!\n",
      "ğŸ’¡ Next steps:\n",
      "   1. Test the API: python run.py --mode local\n",
      "   2. Upload an image: curl -X POST http://localhost:8000/predict -F 'image=@car_image.jpg'\n",
      "   3. Deploy with Docker: python run.py --mode docker\n"
     ]
    }
   ],
   "source": [
    "# =======================================\n",
    "# ğŸ“ MODEL EXPORT AND DEPLOYMENT PREPARATION\n",
    "# =======================================\n",
    "\n",
    "import json\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "def save_model_and_metadata():\n",
    "    \"\"\"\n",
    "    Save the trained model and generate necessary metadata for deployment\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"ğŸ’¾ Saving Model and Generating Deployment Files...\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # Ensure models directory exists\n",
    "    os.makedirs('models', exist_ok=True)\n",
    "    \n",
    "    # 1. Save as H5 format (compatible with existing API - but will show deprecation warning)\n",
    "    model_h5_path = 'car_classification_model.h5'\n",
    "    model.save(model_h5_path)\n",
    "    file_size = Path(model_h5_path).stat().st_size / (1024*1024)\n",
    "    print(f\"âœ… Model saved as H5: {model_h5_path} ({file_size:.1f} MB)\")\n",
    "    print(\"   âš ï¸ H5 format is legacy - consider using .keras format for new projects\")\n",
    "    \n",
    "    # 1b. Save as native Keras format (recommended)\n",
    "    model_keras_path = 'best_car_model.keras'\n",
    "    model.save(model_keras_path)\n",
    "    keras_file_size = Path(model_keras_path).stat().st_size / (1024*1024)\n",
    "    print(f\"âœ… Model saved as Keras: {model_keras_path} ({keras_file_size:.1f} MB)\")\n",
    "    \n",
    "    # 2. Save as SavedModel format (for TensorFlow Serving/TF Lite)\n",
    "    savedmodel_path = 'models/car_classification_savedmodel'\n",
    "    try:\n",
    "        # Use model.export() for SavedModel format in newer TensorFlow versions\n",
    "        if hasattr(model, 'export'):\n",
    "            model.export(savedmodel_path)\n",
    "            print(f\"âœ… Model exported as SavedModel: {savedmodel_path}\")\n",
    "        else:\n",
    "            # Fallback for older TensorFlow versions\n",
    "            tf.saved_model.save(model, savedmodel_path)\n",
    "            print(f\"âœ… Model saved as SavedModel: {savedmodel_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"âš ï¸ SavedModel export failed: {e}\")\n",
    "        print(\"   Continuing with other formats...\")\n",
    "    \n",
    "    # 3. Generate class mapping for the API\n",
    "    if DATASET_READY:\n",
    "        # Get class names from the dataset\n",
    "        # Since we're using tf.data.Dataset, we need to extract class names differently\n",
    "        if 'train_ds' in globals():\n",
    "            # Get class names from train_ds if available\n",
    "            class_names = train_ds.class_names if hasattr(train_ds, 'class_names') else None\n",
    "        else:\n",
    "            class_names = None\n",
    "            \n",
    "        if class_names is not None:\n",
    "            # Create mapping from class index to class name\n",
    "            class_mapping = {\n",
    "                'index_to_class': {str(i): name for i, name in enumerate(class_names)},\n",
    "                'class_to_index': {name: i for i, name in enumerate(class_names)}\n",
    "            }\n",
    "            print(f\"âœ… Using real Stanford Cars dataset class names\")\n",
    "        else:\n",
    "            # Fallback: try to get class names from directory structure\n",
    "            try:\n",
    "                train_dir = Path(TRAIN_DIR)\n",
    "                class_names = sorted([d.name for d in train_dir.iterdir() if d.is_dir()])\n",
    "                class_mapping = {\n",
    "                    'index_to_class': {str(i): name for i, name in enumerate(class_names)},\n",
    "                    'class_to_index': {name: i for i, name in enumerate(class_names)}\n",
    "                }\n",
    "                print(f\"âœ… Extracted {len(class_names)} class names from directory structure\")\n",
    "            except:\n",
    "                # Ultimate fallback: generic class names\n",
    "                class_mapping = {\n",
    "                    'index_to_class': {str(i): f\"Car_Class_{i+1}\" for i in range(NUM_CLASSES)},\n",
    "                    'class_to_index': {f\"Car_Class_{i+1}\": i for i in range(NUM_CLASSES)}\n",
    "                }\n",
    "                print(f\"âš ï¸ Using generic class names (dataset structure not accessible)\")\n",
    "    else:\n",
    "        # Use demo class names for synthetic data\n",
    "        class_mapping = {\n",
    "            'index_to_class': {str(i): f\"Car_Class_{i+1}\" for i in range(NUM_CLASSES)},\n",
    "            'class_to_index': {f\"Car_Class_{i+1}\": i for i in range(NUM_CLASSES)}\n",
    "        }\n",
    "        print(f\"âœ… Using demo class names (synthetic dataset)\")\n",
    "    \n",
    "    # Save class mapping as JSON\n",
    "    class_mapping_path = 'class_mapping.json'\n",
    "    with open(class_mapping_path, 'w') as f:\n",
    "        json.dump(class_mapping, f, indent=2)\n",
    "    \n",
    "    print(f\"âœ… Class mapping saved: {class_mapping_path}\")\n",
    "    print(f\"ğŸ“Š Total classes: {len(class_mapping['index_to_class'])}\")\n",
    "    \n",
    "    # Display sample class mappings\n",
    "    print(f\"\\nğŸ·ï¸ Sample class mappings:\")\n",
    "    sample_classes = list(class_mapping['index_to_class'].items())[:10]\n",
    "    for idx, class_name in sample_classes:\n",
    "        print(f\"   {idx}: {class_name}\")\n",
    "    if len(class_mapping['index_to_class']) > 10:\n",
    "        print(f\"   ... and {len(class_mapping['index_to_class']) - 10} more classes\")\n",
    "    \n",
    "    return model_h5_path, model_keras_path, savedmodel_path, class_mapping_path\n",
    "\n",
    "def verify_api_compatibility():\n",
    "    \"\"\"\n",
    "    Verify that saved model is compatible with the existing API\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"\\nğŸ”§ Verifying API Compatibility...\")\n",
    "    \n",
    "    try:\n",
    "        # Test loading the model (like the API would)\n",
    "        loaded_model = tf.keras.models.load_model('car_classification_model.h5')\n",
    "        \n",
    "        # Test prediction with sample data matching expected input\n",
    "        test_input = np.random.rand(1, 224, 224, 3)  # Standard input size\n",
    "        prediction = loaded_model.predict(test_input, verbose=0)\n",
    "        \n",
    "        print(f\"âœ… Model loads successfully\")\n",
    "        print(f\"âœ… Prediction shape: {prediction.shape}\")\n",
    "        print(f\"âœ… Expected shape: (1, {NUM_CLASSES})\")\n",
    "        \n",
    "        # Verify class mapping\n",
    "        with open('class_mapping.json', 'r') as f:\n",
    "            loaded_mapping = json.load(f)\n",
    "        \n",
    "        print(f\"âœ… Class mapping loads successfully\")\n",
    "        print(f\"âœ… Number of classes: {len(loaded_mapping['index_to_class'])}\")\n",
    "        \n",
    "        if prediction.shape[1] == len(loaded_mapping['index_to_class']):\n",
    "            print(\"âœ… Model output matches class mapping!\")\n",
    "        else:\n",
    "            print(\"âš ï¸ Warning: Model output doesn't match class mapping size\")\n",
    "        \n",
    "        # Test actual prediction pipeline\n",
    "        sample_prediction = np.argmax(prediction[0])\n",
    "        sample_class = loaded_mapping['index_to_class'][str(sample_prediction)]\n",
    "        print(f\"âœ… Sample prediction: Class {sample_prediction} -> {sample_class}\")\n",
    "        \n",
    "        print(\"ğŸ¯ Model is ready for deployment!\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Compatibility check failed: {e}\")\n",
    "        print(\"ğŸ”§ Please check model saving process\")\n",
    "        return False\n",
    "    \n",
    "    return True\n",
    "\n",
    "# Execute the model saving and preparation pipeline\n",
    "print(\"ğŸš€ STARTING MODEL EXPORT PIPELINE\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Save model and generate deployment files\n",
    "try:\n",
    "    model_files = save_model_and_metadata()\n",
    "    \n",
    "    # Verify API compatibility\n",
    "    compatibility_ok = verify_api_compatibility()\n",
    "    \n",
    "    # Summary\n",
    "    print(f\"\\nğŸ‰ Model Export Complete!\")\n",
    "    print(\"=\" * 50)\n",
    "    print(\"ğŸ“ Generated Files:\")\n",
    "    print(f\"   âœ… {model_files[0]} - H5 model (legacy format)\")\n",
    "    print(f\"   âœ… {model_files[1]} - Keras model (recommended)\")\n",
    "    print(f\"   âœ… {model_files[2]} - SavedModel for production\")\n",
    "    print(f\"   âœ… {model_files[3]} - Class mapping\")\n",
    "    print(f\"   âœ… prediction_example.py - Usage example\")\n",
    "    \n",
    "    if compatibility_ok:\n",
    "        print(f\"\\nğŸš€ Your model is ready for deployment!\")\n",
    "        print(\"ğŸ’¡ Next steps:\")\n",
    "        print(\"   1. Test the API: python run.py --mode local\")\n",
    "        print(\"   2. Upload an image: curl -X POST http://localhost:8000/predict -F 'image=@car_image.jpg'\")\n",
    "        print(\"   3. Deploy with Docker: python run.py --mode docker\")\n",
    "    else:\n",
    "        print(f\"\\nâš ï¸ Please fix compatibility issues before deployment\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"\\nâŒ Model export failed: {e}\")\n",
    "    print(\"ğŸ”§ Please check that the model variable is defined and training completed successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0de8e9bb",
   "metadata": {},
   "source": [
    "# 7. Class Mapping and Model Export\n",
    "\n",
    "## Objective\n",
    "Create class mapping for the Stanford Cars dataset and export the final model for deployment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "29ee77b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“‹ FINAL MODEL SUMMARY\n",
      "=========================\n",
      "ğŸ—ï¸ Architecture: ResNet50-based transfer learning\n",
      "ğŸ“Š Total parameters: 24,820,548\n",
      "ğŸ¯ Output classes: 196\n",
      "ğŸ“ Input shape: (None, 224, 224, 3)\n",
      "âš¡ TensorFlow version: 2.19.0\n",
      "ğŸ”§ Mixed precision: Enabled\n",
      "\n",
      "ğŸ’¾ Model Files:\n",
      "   âœ… best_car_model.keras (250.5MB) - Main model file (TensorFlow 2.19 format)\n",
      "   âœ… class_mapping.json (0.0MB) - Class name mappings\n",
      "\n",
      "ğŸ¯ PERFORMANCE SUMMARY:\n",
      "   Test Accuracy: 48.73%\n",
      "   Test Top-5 Accuracy: 76.23%\n",
      "   Model Status: Needs Improvement\n",
      "\n",
      "ğŸš€ DEPLOYMENT INFORMATION:\n",
      "   1. Load model: tf.keras.models.load_model('best_car_model.keras')\n",
      "   2. Preprocess image: Resize to 224x224, normalize to [0,1]\n",
      "   3. Predict: model.predict(preprocessed_image)\n",
      "   4. Get class name: Use class_mapping.json for label lookup\n",
      "\n",
      "ğŸ“± API INTEGRATION:\n",
      "   â€¢ FastAPI server: run_api.py or standalone_api.py\n",
      "   â€¢ Docker deployment: docker-compose up\n",
      "   â€¢ Model format: Compatible with TensorFlow Serving\n",
      "\n",
      "ğŸ’¡ QUICK USAGE EXAMPLE:\n",
      "\n",
      "# Load model\n",
      "model = tf.keras.models.load_model('best_car_model.keras')\n",
      "\n",
      "# Load class mapping\n",
      "with open('class_mapping.json', 'r') as f:\n",
      "    class_mapping = json.load(f)\n",
      "\n",
      "# Preprocess image\n",
      "image = tf.keras.utils.load_img('car_image.jpg', target_size=(224, 224))\n",
      "image_array = tf.keras.utils.img_to_array(image)\n",
      "image_array = tf.expand_dims(image_array, 0) / 255.0\n",
      "\n",
      "# Predict\n",
      "predictions = model.predict(image_array)\n",
      "predicted_class_idx = np.argmax(predictions[0])\n",
      "predicted_class_name = class_mapping[str(predicted_class_idx)]\n",
      "confidence = predictions[0][predicted_class_idx]\n",
      "\n",
      "print(f\"Predicted: {predicted_class_name} ({confidence:.2%} confidence)\")\n",
      "\n",
      "\n",
      "âœ… Car Type Classification System Ready!\n",
      "ğŸ‰ Model successfully trained and saved\n",
      "\n",
      "ğŸ—ï¸ Model Architecture Summary:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ<span style=\"font-weight: bold\"> Layer (type)                    </span>â”ƒ<span style=\"font-weight: bold\"> Output Shape           </span>â”ƒ<span style=\"font-weight: bold\">       Param # </span>â”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚ resnet50 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)           â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)     â”‚    <span style=\"color: #00af00; text-decoration-color: #00af00\">23,587,712</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ global_average_pooling2d        â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)           â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)        â”‚                        â”‚               â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)           â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            â”‚     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,049,088</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ batch_normalization             â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            â”‚         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            â”‚                        â”‚               â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            â”‚       <span style=\"color: #00af00; text-decoration-color: #00af00\">131,328</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ predictions_fixed (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)       â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">196</span>)            â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">50,372</span> â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
       "</pre>\n"
      ],
      "text/plain": [
       "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚ resnet50 (\u001b[38;5;33mFunctional\u001b[0m)           â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m2048\u001b[0m)     â”‚    \u001b[38;5;34m23,587,712\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ global_average_pooling2d        â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2048\u001b[0m)           â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”‚ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)        â”‚                        â”‚               â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout (\u001b[38;5;33mDropout\u001b[0m)               â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2048\u001b[0m)           â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense (\u001b[38;5;33mDense\u001b[0m)                   â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            â”‚     \u001b[38;5;34m1,049,088\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ batch_normalization             â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            â”‚         \u001b[38;5;34m2,048\u001b[0m â”‚\n",
       "â”‚ (\u001b[38;5;33mBatchNormalization\u001b[0m)            â”‚                        â”‚               â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            â”‚       \u001b[38;5;34m131,328\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ predictions_fixed (\u001b[38;5;33mDense\u001b[0m)       â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m196\u001b[0m)            â”‚        \u001b[38;5;34m50,372\u001b[0m â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">45,146,834</span> (172.22 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m45,146,834\u001b[0m (172.22 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">10,163,140</span> (38.77 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m10,163,140\u001b[0m (38.77 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">14,657,408</span> (55.91 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m14,657,408\u001b[0m (55.91 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">20,326,286</span> (77.54 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m20,326,286\u001b[0m (77.54 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# =======================================\n",
    "# ğŸ“‹ FINAL MODEL SUMMARY AND DEPLOYMENT\n",
    "# =======================================\n",
    "\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "print(\"ğŸ“‹ FINAL MODEL SUMMARY\")\n",
    "print(\"=\" * 25)\n",
    "\n",
    "# Model information\n",
    "print(f\"ğŸ—ï¸ Architecture: ResNet50-based transfer learning\")\n",
    "print(f\"ğŸ“Š Total parameters: {model.count_params():,}\")\n",
    "print(f\"ğŸ¯ Output classes: {model.output_shape[-1]}\")\n",
    "print(f\"ğŸ“ Input shape: {model.input_shape}\")\n",
    "print(f\"âš¡ TensorFlow version: {tf.__version__}\")\n",
    "print(f\"ğŸ”§ Mixed precision: {'Enabled' if tf.keras.mixed_precision.global_policy().name != 'float32' else 'Disabled'}\")\n",
    "\n",
    "# Check model files\n",
    "print(f\"\\nğŸ’¾ Model Files:\")\n",
    "model_files = {\n",
    "    'best_car_model.keras': 'Main model file (TensorFlow 2.19 format)',\n",
    "    'class_mapping.json': 'Class name mappings',\n",
    "}\n",
    "\n",
    "for filename, description in model_files.items():\n",
    "    file_path = Path(filename)\n",
    "    if file_path.exists():\n",
    "        size = file_path.stat().st_size / (1024*1024)  # MB\n",
    "        print(f\"   âœ… {filename} ({size:.1f}MB) - {description}\")\n",
    "    else:\n",
    "        print(f\"   âŒ {filename} - {description} (missing)\")\n",
    "\n",
    "# Create class mapping if dataset available and file doesn't exist\n",
    "if DATASET_READY and not Path('class_mapping.json').exists():\n",
    "    print(f\"\\nğŸ“ Creating class mapping...\")\n",
    "    class_names = sorted([d.name for d in TRAIN_DIR.iterdir() if d.is_dir()])\n",
    "    class_mapping = {i: name for i, name in enumerate(class_names)}\n",
    "    \n",
    "    with open('class_mapping.json', 'w') as f:\n",
    "        json.dump(class_mapping, f, indent=2)\n",
    "    print(f\"âœ… Class mapping saved with {len(class_mapping)} classes\")\n",
    "\n",
    "# Performance summary (if evaluation was done)\n",
    "if DATASET_READY and 'test_results' in globals():\n",
    "    print(f\"\\nğŸ¯ PERFORMANCE SUMMARY:\")\n",
    "    print(f\"   Test Accuracy: {test_results['accuracy']*100:.2f}%\")\n",
    "    if 'top_5_accuracy' in test_results:\n",
    "        print(f\"   Test Top-5 Accuracy: {test_results['top_5_accuracy']*100:.2f}%\")\n",
    "    print(f\"   Model Status: {'Production Ready' if test_results['accuracy'] > 0.7 else 'Needs Improvement'}\")\n",
    "\n",
    "# Deployment information\n",
    "print(f\"\\nğŸš€ DEPLOYMENT INFORMATION:\")\n",
    "print(f\"   1. Load model: tf.keras.models.load_model('best_car_model.keras')\")\n",
    "print(f\"   2. Preprocess image: Resize to 224x224, normalize to [0,1]\")\n",
    "print(f\"   3. Predict: model.predict(preprocessed_image)\")\n",
    "print(f\"   4. Get class name: Use class_mapping.json for label lookup\")\n",
    "\n",
    "print(f\"\\nğŸ“± API INTEGRATION:\")\n",
    "print(f\"   â€¢ FastAPI server: run_api.py or standalone_api.py\")\n",
    "print(f\"   â€¢ Docker deployment: docker-compose up\")\n",
    "print(f\"   â€¢ Model format: Compatible with TensorFlow Serving\")\n",
    "\n",
    "# Usage example\n",
    "print(f\"\\nğŸ’¡ QUICK USAGE EXAMPLE:\")\n",
    "print(f\"\"\"\n",
    "# Load model\n",
    "model = tf.keras.models.load_model('best_car_model.keras')\n",
    "\n",
    "# Load class mapping\n",
    "with open('class_mapping.json', 'r') as f:\n",
    "    class_mapping = json.load(f)\n",
    "\n",
    "# Preprocess image\n",
    "image = tf.keras.utils.load_img('car_image.jpg', target_size=(224, 224))\n",
    "image_array = tf.keras.utils.img_to_array(image)\n",
    "image_array = tf.expand_dims(image_array, 0) / 255.0\n",
    "\n",
    "# Predict\n",
    "predictions = model.predict(image_array)\n",
    "predicted_class_idx = np.argmax(predictions[0])\n",
    "predicted_class_name = class_mapping[str(predicted_class_idx)]\n",
    "confidence = predictions[0][predicted_class_idx]\n",
    "\n",
    "print(f\"Predicted: {{predicted_class_name}} ({{confidence:.2%}} confidence)\")\n",
    "\"\"\")\n",
    "\n",
    "print(f\"\\nâœ… Car Type Classification System Ready!\")\n",
    "print(f\"ğŸ‰ Model successfully {'loaded from existing file' if SKIP_TRAINING else 'trained and saved'}\")\n",
    "\n",
    "# Display final model architecture summary\n",
    "print(f\"\\nğŸ—ï¸ Model Architecture Summary:\")\n",
    "try:\n",
    "    model.summary()\n",
    "except:\n",
    "    print(\"Model summary not available - check model loading\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9f1bd5f",
   "metadata": {},
   "source": [
    "# 8. Environment Verification\n",
    "\n",
    "## Package Versions\n",
    "This section captures the exact package versions used for model training to ensure reproducibility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8c0cd281",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¦ Installed Package Versions:\n",
      "==================================================\n",
      "ğŸ”‘ Key Packages:\n",
      "  fastapi==0.116.1\n",
      "  keras==3.10.0\n",
      "  numpy==1.26.4\n",
      "  Pillow==10.0.0\n",
      "  tensorflow==2.19.0\n",
      "  uvicorn==0.35.0\n",
      "\n",
      "ğŸ“‹ All Packages (158 total):\n",
      "  absl-py==2.3.1\n",
      "  annotated-types==0.7.0\n",
      "  anyio==4.9.0\n",
      "  argon2-cffi==25.1.0\n",
      "  argon2-cffi-bindings==21.2.0\n",
      "  arrow==1.3.0\n",
      "  asttokens==3.0.0\n",
      "  astunparse==1.6.3\n",
      "  async-lru==2.0.5\n",
      "  attrs==25.3.0\n",
      "  babel==2.17.0\n",
      "  beautifulsoup4==4.13.4\n",
      "  bleach==6.2.0\n",
      "  certifi==2025.7.14\n",
      "  cffi==1.17.1\n",
      "  charset-normalizer==3.4.2\n",
      "  click==8.2.1\n",
      "  comm==0.2.2\n",
      "  contourpy==1.3.2\n",
      "  cycler==0.12.1\n",
      "  debugpy==1.8.15\n",
      "  decorator==5.2.1\n",
      "  defusedxml==0.7.1\n",
      "  executing==2.2.0\n",
      "  fastapi==0.116.1\n",
      "  fastjsonschema==2.21.1\n",
      "  flatbuffers==25.2.10\n",
      "  fonttools==4.59.0\n",
      "  fqdn==1.5.1\n",
      "  gast==0.6.0\n",
      "  google-pasta==0.2.0\n",
      "  grpcio==1.73.1\n",
      "  h11==0.16.0\n",
      "  h5py==3.14.0\n",
      "  httpcore==1.0.9\n",
      "  httpx==0.28.1\n",
      "  idna==3.10\n",
      "  iniconfig==2.1.0\n",
      "  ipykernel==6.25.2\n",
      "  ipython==9.4.0\n",
      "  ipython_pygments_lexers==1.1.1\n",
      "  ipywidgets==8.1.7\n",
      "  isoduration==20.11.0\n",
      "  jedi==0.19.2\n",
      "  Jinja2==3.1.6\n",
      "  joblib==1.5.1\n",
      "  json5==0.12.0\n",
      "  jsonpointer==3.0.0\n",
      "  jsonschema==4.25.0\n",
      "  jsonschema-specifications==2025.4.1\n",
      "  jupyter==1.0.0\n",
      "  jupyter-console==6.6.3\n",
      "  jupyter-events==0.12.0\n",
      "  jupyter-lsp==2.2.6\n",
      "  jupyter_client==8.6.3\n",
      "  jupyter_core==5.8.1\n",
      "  jupyter_server==2.16.0\n",
      "  jupyter_server_terminals==0.5.3\n",
      "  jupyterlab==4.4.5\n",
      "  jupyterlab_pygments==0.3.0\n",
      "  jupyterlab_server==2.27.3\n",
      "  jupyterlab_widgets==3.0.15\n",
      "  kagglehub==0.3.12\n",
      "  keras==3.10.0\n",
      "  kiwisolver==1.4.8\n",
      "  lark==1.2.2\n",
      "  libclang==18.1.1\n",
      "  Markdown==3.8.2\n",
      "  markdown-it-py==3.0.0\n",
      "  MarkupSafe==3.0.2\n",
      "  matplotlib==3.10.3\n",
      "  matplotlib-inline==0.1.7\n",
      "  mdurl==0.1.2\n",
      "  mistune==3.1.3\n",
      "  ml_dtypes==0.5.1\n",
      "  namex==0.1.0\n",
      "  nbclient==0.10.2\n",
      "  nbconvert==7.16.6\n",
      "  nbformat==5.10.4\n",
      "  nest-asyncio==1.6.0\n",
      "  notebook==7.0.3\n",
      "  notebook_shim==0.2.4\n",
      "  numpy==1.26.4\n",
      "  opt_einsum==3.4.0\n",
      "  optree==0.16.0\n",
      "  overrides==7.7.0\n",
      "  packaging==25.0\n",
      "  pandas==2.3.1\n",
      "  pandocfilters==1.5.1\n",
      "  parso==0.8.4\n",
      "  pexpect==4.9.0\n",
      "  Pillow==10.0.0\n",
      "  platformdirs==4.3.8\n",
      "  pluggy==1.6.0\n",
      "  prometheus_client==0.22.1\n",
      "  prompt_toolkit==3.0.51\n",
      "  protobuf==5.29.5\n",
      "  psutil==7.0.0\n",
      "  ptyprocess==0.7.0\n",
      "  pure_eval==0.2.3\n",
      "  pycparser==2.22\n",
      "  pydantic==2.11.7\n",
      "  pydantic_core==2.33.2\n",
      "  Pygments==2.19.2\n",
      "  pyparsing==3.2.3\n",
      "  pytest==7.4.2\n",
      "  pytest-asyncio==0.21.1\n",
      "  python-dateutil==2.9.0.post0\n",
      "  python-dotenv==1.0.0\n",
      "  python-json-logger==3.3.0\n",
      "  python-multipart==0.0.6\n",
      "  pytz==2025.2\n",
      "  PyYAML==6.0.2\n",
      "  pyzmq==27.0.0\n",
      "  qtconsole==5.6.1\n",
      "  QtPy==2.4.3\n",
      "  referencing==0.36.2\n",
      "  requests==2.31.0\n",
      "  rfc3339-validator==0.1.4\n",
      "  rfc3986-validator==0.1.1\n",
      "  rfc3987-syntax==1.1.0\n",
      "  rich==14.0.0\n",
      "  rpds-py==0.26.0\n",
      "  scikit-learn==1.7.1\n",
      "  scipy==1.16.0\n",
      "  seaborn==0.13.2\n",
      "  Send2Trash==1.8.3\n",
      "  setuptools==80.9.0\n",
      "  six==1.17.0\n",
      "  sniffio==1.3.1\n",
      "  soupsieve==2.7\n",
      "  stack-data==0.6.3\n",
      "  starlette==0.47.2\n",
      "  tensorboard==2.19.0\n",
      "  tensorboard-data-server==0.7.2\n",
      "  tensorflow==2.19.0\n",
      "  termcolor==3.1.0\n",
      "  terminado==0.18.1\n",
      "  threadpoolctl==3.6.0\n",
      "  tinycss2==1.4.0\n",
      "  tornado==6.5.1\n",
      "  tqdm==4.67.1\n",
      "  traitlets==5.14.3\n",
      "  types-python-dateutil==2.9.0.20250708\n",
      "  typing-inspection==0.4.1\n",
      "  typing_extensions==4.14.1\n",
      "  tzdata==2025.2\n",
      "  uri-template==1.3.0\n",
      "  urllib3==2.5.0\n",
      "  uvicorn==0.35.0\n",
      "  wcwidth==0.2.13\n",
      "  webcolors==24.11.1\n",
      "  webencodings==0.5.1\n",
      "  websocket-client==1.8.0\n",
      "  Werkzeug==3.1.3\n",
      "  wheel==0.45.1\n",
      "  widgetsnbextension==4.0.14\n",
      "  wrapt==1.17.2\n",
      "\n",
      "âœ… Environment verification complete!\n",
      "ğŸ’¡ These versions should match requirements.txt for reproducibility\n",
      "ğŸ”‘ Key Packages:\n",
      "  fastapi==0.116.1\n",
      "  keras==3.10.0\n",
      "  numpy==1.26.4\n",
      "  Pillow==10.0.0\n",
      "  tensorflow==2.19.0\n",
      "  uvicorn==0.35.0\n",
      "\n",
      "ğŸ“‹ All Packages (158 total):\n",
      "  absl-py==2.3.1\n",
      "  annotated-types==0.7.0\n",
      "  anyio==4.9.0\n",
      "  argon2-cffi==25.1.0\n",
      "  argon2-cffi-bindings==21.2.0\n",
      "  arrow==1.3.0\n",
      "  asttokens==3.0.0\n",
      "  astunparse==1.6.3\n",
      "  async-lru==2.0.5\n",
      "  attrs==25.3.0\n",
      "  babel==2.17.0\n",
      "  beautifulsoup4==4.13.4\n",
      "  bleach==6.2.0\n",
      "  certifi==2025.7.14\n",
      "  cffi==1.17.1\n",
      "  charset-normalizer==3.4.2\n",
      "  click==8.2.1\n",
      "  comm==0.2.2\n",
      "  contourpy==1.3.2\n",
      "  cycler==0.12.1\n",
      "  debugpy==1.8.15\n",
      "  decorator==5.2.1\n",
      "  defusedxml==0.7.1\n",
      "  executing==2.2.0\n",
      "  fastapi==0.116.1\n",
      "  fastjsonschema==2.21.1\n",
      "  flatbuffers==25.2.10\n",
      "  fonttools==4.59.0\n",
      "  fqdn==1.5.1\n",
      "  gast==0.6.0\n",
      "  google-pasta==0.2.0\n",
      "  grpcio==1.73.1\n",
      "  h11==0.16.0\n",
      "  h5py==3.14.0\n",
      "  httpcore==1.0.9\n",
      "  httpx==0.28.1\n",
      "  idna==3.10\n",
      "  iniconfig==2.1.0\n",
      "  ipykernel==6.25.2\n",
      "  ipython==9.4.0\n",
      "  ipython_pygments_lexers==1.1.1\n",
      "  ipywidgets==8.1.7\n",
      "  isoduration==20.11.0\n",
      "  jedi==0.19.2\n",
      "  Jinja2==3.1.6\n",
      "  joblib==1.5.1\n",
      "  json5==0.12.0\n",
      "  jsonpointer==3.0.0\n",
      "  jsonschema==4.25.0\n",
      "  jsonschema-specifications==2025.4.1\n",
      "  jupyter==1.0.0\n",
      "  jupyter-console==6.6.3\n",
      "  jupyter-events==0.12.0\n",
      "  jupyter-lsp==2.2.6\n",
      "  jupyter_client==8.6.3\n",
      "  jupyter_core==5.8.1\n",
      "  jupyter_server==2.16.0\n",
      "  jupyter_server_terminals==0.5.3\n",
      "  jupyterlab==4.4.5\n",
      "  jupyterlab_pygments==0.3.0\n",
      "  jupyterlab_server==2.27.3\n",
      "  jupyterlab_widgets==3.0.15\n",
      "  kagglehub==0.3.12\n",
      "  keras==3.10.0\n",
      "  kiwisolver==1.4.8\n",
      "  lark==1.2.2\n",
      "  libclang==18.1.1\n",
      "  Markdown==3.8.2\n",
      "  markdown-it-py==3.0.0\n",
      "  MarkupSafe==3.0.2\n",
      "  matplotlib==3.10.3\n",
      "  matplotlib-inline==0.1.7\n",
      "  mdurl==0.1.2\n",
      "  mistune==3.1.3\n",
      "  ml_dtypes==0.5.1\n",
      "  namex==0.1.0\n",
      "  nbclient==0.10.2\n",
      "  nbconvert==7.16.6\n",
      "  nbformat==5.10.4\n",
      "  nest-asyncio==1.6.0\n",
      "  notebook==7.0.3\n",
      "  notebook_shim==0.2.4\n",
      "  numpy==1.26.4\n",
      "  opt_einsum==3.4.0\n",
      "  optree==0.16.0\n",
      "  overrides==7.7.0\n",
      "  packaging==25.0\n",
      "  pandas==2.3.1\n",
      "  pandocfilters==1.5.1\n",
      "  parso==0.8.4\n",
      "  pexpect==4.9.0\n",
      "  Pillow==10.0.0\n",
      "  platformdirs==4.3.8\n",
      "  pluggy==1.6.0\n",
      "  prometheus_client==0.22.1\n",
      "  prompt_toolkit==3.0.51\n",
      "  protobuf==5.29.5\n",
      "  psutil==7.0.0\n",
      "  ptyprocess==0.7.0\n",
      "  pure_eval==0.2.3\n",
      "  pycparser==2.22\n",
      "  pydantic==2.11.7\n",
      "  pydantic_core==2.33.2\n",
      "  Pygments==2.19.2\n",
      "  pyparsing==3.2.3\n",
      "  pytest==7.4.2\n",
      "  pytest-asyncio==0.21.1\n",
      "  python-dateutil==2.9.0.post0\n",
      "  python-dotenv==1.0.0\n",
      "  python-json-logger==3.3.0\n",
      "  python-multipart==0.0.6\n",
      "  pytz==2025.2\n",
      "  PyYAML==6.0.2\n",
      "  pyzmq==27.0.0\n",
      "  qtconsole==5.6.1\n",
      "  QtPy==2.4.3\n",
      "  referencing==0.36.2\n",
      "  requests==2.31.0\n",
      "  rfc3339-validator==0.1.4\n",
      "  rfc3986-validator==0.1.1\n",
      "  rfc3987-syntax==1.1.0\n",
      "  rich==14.0.0\n",
      "  rpds-py==0.26.0\n",
      "  scikit-learn==1.7.1\n",
      "  scipy==1.16.0\n",
      "  seaborn==0.13.2\n",
      "  Send2Trash==1.8.3\n",
      "  setuptools==80.9.0\n",
      "  six==1.17.0\n",
      "  sniffio==1.3.1\n",
      "  soupsieve==2.7\n",
      "  stack-data==0.6.3\n",
      "  starlette==0.47.2\n",
      "  tensorboard==2.19.0\n",
      "  tensorboard-data-server==0.7.2\n",
      "  tensorflow==2.19.0\n",
      "  termcolor==3.1.0\n",
      "  terminado==0.18.1\n",
      "  threadpoolctl==3.6.0\n",
      "  tinycss2==1.4.0\n",
      "  tornado==6.5.1\n",
      "  tqdm==4.67.1\n",
      "  traitlets==5.14.3\n",
      "  types-python-dateutil==2.9.0.20250708\n",
      "  typing-inspection==0.4.1\n",
      "  typing_extensions==4.14.1\n",
      "  tzdata==2025.2\n",
      "  uri-template==1.3.0\n",
      "  urllib3==2.5.0\n",
      "  uvicorn==0.35.0\n",
      "  wcwidth==0.2.13\n",
      "  webcolors==24.11.1\n",
      "  webencodings==0.5.1\n",
      "  websocket-client==1.8.0\n",
      "  Werkzeug==3.1.3\n",
      "  wheel==0.45.1\n",
      "  widgetsnbextension==4.0.14\n",
      "  wrapt==1.17.2\n",
      "\n",
      "âœ… Environment verification complete!\n",
      "ğŸ’¡ These versions should match requirements.txt for reproducibility\n"
     ]
    }
   ],
   "source": [
    "# Environment verification - capture package versions for reproducibility\n",
    "print(\"ğŸ“¦ Installed Package Versions:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "# Get pip freeze output\n",
    "result = subprocess.run([sys.executable, '-m', 'pip', 'freeze'], \n",
    "                       capture_output=True, text=True)\n",
    "\n",
    "# Display package versions\n",
    "if result.returncode == 0:\n",
    "    packages = result.stdout.strip().split('\\n')\n",
    "    # Show key packages first\n",
    "    key_packages = ['tensorflow', 'keras', 'numpy', 'pillow', 'fastapi', 'uvicorn']\n",
    "    \n",
    "    print(\"ğŸ”‘ Key Packages:\")\n",
    "    for package in packages:\n",
    "        package_name = package.split('==')[0].lower()\n",
    "        if any(key in package_name for key in key_packages):\n",
    "            print(f\"  {package}\")\n",
    "    \n",
    "    print(f\"\\nğŸ“‹ All Packages ({len(packages)} total):\")\n",
    "    for package in packages:\n",
    "        print(f\"  {package}\")\n",
    "else:\n",
    "    print(f\"âŒ Error running pip freeze: {result.stderr}\")\n",
    "\n",
    "print(f\"\\nâœ… Environment verification complete!\")\n",
    "print(f\"ğŸ’¡ These versions should match requirements.txt for reproducibility\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
